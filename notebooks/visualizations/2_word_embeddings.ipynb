{"cells":[{"cell_type":"markdown","metadata":{"id":"E2FqD4jumqVb"},"source":["# Notebook 2: Word Embeddings - Words as Vectors\n","\n","## Making Computers Understand Word Meanings\n","\n","**The Problem:** Computers see words as just text: \"cat\" = ['c','a','t']\n","\n","**The Solution:** Turn words into numbers that capture meaning!\n","\n","---\n","\n","### What We'll Learn:\n","1. Why words need to be vectors\n","2. Train Word2Vec on Shakespeare\n","3. Find similar words\n","4. Visualize word relationships in 3D!\n","5. Do word math: king - man + woman = ?"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZEncMSvmqVc","executionInfo":{"status":"ok","timestamp":1756198844909,"user_tz":-180,"elapsed":41145,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}},"outputId":"8f68390e-13ad-4fab-86dc-cef163eee910"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# Install required packages\n","!pip install plotly gensim scikit-learn -q"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"arw3iMyImqVe","executionInfo":{"status":"error","timestamp":1756198844928,"user_tz":-180,"elapsed":13,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}},"outputId":"89d69f89-22e0-4561-eddf-b797bb189983"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:_plotly_utils.optional_imports:Error importing optional module pandas\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/_plotly_utils/optional_imports.py\", line 28, in get_module\n","    return import_module(name)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n","  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n","  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n","  File \"/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\", line 37, in <module>\n","    from pandas._config import (\n","  File \"/usr/local/lib/python3.12/dist-packages/pandas/_config/__init__.py\", line 20, in <module>\n","    from pandas._config import config\n","  File \"/usr/local/lib/python3.12/dist-packages/pandas/_config/config.py\", line 68, in <module>\n","    from pandas._typing import (\n","  File \"/usr/local/lib/python3.12/dist-packages/pandas/_typing.py\", line 198, in <module>\n","    np.random.Generator,\n","    ^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\", line 337, in __getattr__\n","    public_symbols = globals().keys() | {'testing'}\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\", line 180, in <module>\n","    from . import _pickle\n","  File \"/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\", line 1, in <module>\n","    from .mtrand import RandomState\n","  File \"numpy/random/mtrand.pyx\", line 1, in init numpy.random.mtrand\n","ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n"]},{"output_type":"error","ename":"ImportError","evalue":"Plotly express requires pandas to be installed.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3423487851.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/plotly/express/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptional_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pandas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \"\"\"\\\n\u001b[1;32m     11\u001b[0m Plotly express requires pandas to be installed.\"\"\"\n","\u001b[0;31mImportError\u001b[0m: Plotly express requires pandas to be installed.","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from gensim.models import Word2Vec\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from shakespeare_utils import download_shakespeare_sonnets, tokenize\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"mVY5IsJhmqVf"},"source":["## Part 1: Why Do We Need Word Vectors?\n","\n","Let's see the problem with treating words as just text:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cEReoUjamqVf","executionInfo":{"status":"aborted","timestamp":1756198844935,"user_tz":-180,"elapsed":2,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["# Problem: How similar are these words?\n","word1 = \"king\"\n","word2 = \"queen\"\n","word3 = \"book\"\n","\n","print(\"As text strings:\")\n","print(f\"  '{word1}' and '{word2}' share {len(set(word1) & set(word2))} letters\")\n","print(f\"  '{word1}' and '{word3}' share {len(set(word1) & set(word3))} letters\")\n","print(\"\\n‚ùå This doesn't capture meaning at all!\")\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"\\nWhat we want:\")\n","print(\"  'king' and 'queen' should be VERY similar (both royalty)\")\n","print(\"  'king' and 'book' should be LESS similar (different concepts)\")\n","print(\"\\n‚úÖ Word vectors can do this!\")"]},{"cell_type":"markdown","metadata":{"id":"CG7UqP2vmqVg"},"source":["## Part 2: One-Hot Encoding (The Old Way)\n","\n","First attempt: Give each word a unique number"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1NGas2gmqVg","executionInfo":{"status":"aborted","timestamp":1756198844938,"user_tz":-180,"elapsed":41457,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["# Simple vocabulary\n","vocab = [\"king\", \"queen\", \"man\", \"woman\", \"book\"]\n","\n","# One-hot encoding\n","def one_hot_encode(word, vocab):\n","    vector = [0] * len(vocab)\n","    if word in vocab:\n","        vector[vocab.index(word)] = 1\n","    return vector\n","\n","# Encode our words\n","print(\"One-Hot Encoding:\")\n","print(\"=\"*30)\n","for word in vocab:\n","    vec = one_hot_encode(word, vocab)\n","    print(f\"{word:6} = {vec}\")\n","\n","print(\"\\n‚ùå Problems:\")\n","print(\"  1. Vectors are HUGE (one dimension per word)\")\n","print(\"  2. All words are equally different from each other\")\n","print(\"  3. Can't capture any relationships\")"]},{"cell_type":"markdown","metadata":{"id":"87qS5-xNmqVg"},"source":["## Part 3: Word2Vec - Learning Meaning from Context\n","\n","**Key Idea:** Words that appear in similar contexts have similar meanings!\n","\n","\"You shall know a word by the company it keeps\" - J.R. Firth (1957)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20bXamrGmqVg","executionInfo":{"status":"aborted","timestamp":1756198844941,"user_tz":-180,"elapsed":41453,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["# Load Shakespeare text\n","text = download_shakespeare_sonnets()\n","words = tokenize(text)\n","\n","# Prepare sentences for Word2Vec\n","# Split into sentences (simple approach)\n","sentences = []\n","current_sentence = []\n","\n","for word in words:\n","    current_sentence.append(word)\n","    # End sentence at punctuation or after 15 words\n","    if len(current_sentence) >= 15 or word in ['.', '!', '?']:\n","        if len(current_sentence) > 2:  # Keep sentences with at least 3 words\n","            sentences.append(current_sentence[:])\n","        current_sentence = []\n","\n","print(f\"Created {len(sentences)} sentences\")\n","print(f\"\\nExample sentences:\")\n","for i, sent in enumerate(sentences[:3]):\n","    print(f\"  {i+1}. {' '.join(sent[:10])}...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdxMVXCcmqVh","executionInfo":{"status":"aborted","timestamp":1756198844943,"user_tz":-180,"elapsed":41448,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["# Train Word2Vec model\n","print(\"Training Word2Vec...\")\n","\n","# Better parameters for learning\n","model = Word2Vec(\n","    sentences=sentences,\n","    vector_size=50,      # Each word becomes a 50-number vector\n","    window=5,            # Look at 5 words before and after\n","    min_count=2,         # Lower threshold to include more words\n","    workers=1,           # Use 1 CPU core\n","    seed=42,             # For reproducibility\n","    epochs=100,          # More training iterations\n","    sg=1,                # Use skip-gram (better for small datasets)\n","    alpha=0.025,         # Learning rate\n","    min_alpha=0.0001     # Minimum learning rate\n",")\n","\n","print(f\"‚úÖ Trained on {len(model.wv)} words\")\n","print(f\"Each word is now a {model.wv.vector_size}-dimensional vector!\")\n","\n","# Show an example vector\n","if 'love' in model.wv:\n","    love_vector = model.wv['love']\n","    print(f\"\\nThe word 'love' as a vector (first 10 numbers):\")\n","    print(np.round(love_vector[:10], 3))"]},{"cell_type":"markdown","metadata":{"id":"ckvsEUstmqVh"},"source":["## Part 4: Finding Similar Words\n","\n","Now we can find words with similar meanings!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qR-d3cv7mqVh","executionInfo":{"status":"aborted","timestamp":1756198844946,"user_tz":-180,"elapsed":41446,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["def find_similar_words(word, model, top_n=10):\n","    \"\"\"Find words with similar meanings.\"\"\"\n","    if word not in model.wv:\n","        print(f\"Word '{word}' not in vocabulary!\")\n","        return []\n","\n","    similar = model.wv.most_similar(word, topn=top_n)\n","    return similar\n","\n","# Test with different words - use more common words from sonnets\n","test_words = ['love', 'time', 'beauty', 'death']\n","\n","for word in test_words:\n","    if word in model.wv:\n","        print(f\"\\nWords similar to '{word}':\")\n","        similar = find_similar_words(word, model, top_n=5)\n","        for sim_word, score in similar:\n","            bar = '‚ñà' * int(score * 10)\n","            print(f\"  {sim_word:12} {bar} {score:.2f}\")\n","    else:\n","        print(f\"\\nWord '{word}' not in vocabulary\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOhTcC9hmqVi","executionInfo":{"status":"aborted","timestamp":1756198844950,"user_tz":-180,"elapsed":41443,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["# Visualize similarity scores\n","def plot_similarity(word, model):\n","    similar = find_similar_words(word, model, top_n=10)\n","\n","    if not similar:\n","        return\n","\n","    words, scores = zip(*similar)\n","\n","    fig = go.Figure(data=[\n","        go.Bar(\n","            x=list(scores),\n","            y=list(words),\n","            orientation='h',\n","            marker=dict(\n","                color=list(scores),\n","                colorscale='Viridis',\n","                showscale=False\n","            ),\n","            text=[f'{s:.2f}' for s in scores],\n","            textposition='auto',\n","        )\n","    ])\n","\n","    fig.update_layout(\n","        title=f\"Words Most Similar to '{word}'\",\n","        xaxis_title=\"Similarity Score (0-1)\",\n","        yaxis_title=\"Word\",\n","        height=400,\n","        xaxis=dict(range=[0, 1])\n","    )\n","\n","    fig.show()\n","\n","# Visualize - use a common word from sonnets\n","plot_similarity('love', model)"]},{"cell_type":"markdown","metadata":{"id":"ZXeWFi8CmqVi"},"source":["## Part 5: Visualizing Word Space in 3D\n","\n","Let's see how words cluster in space!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0JiYrjImqVi","executionInfo":{"status":"aborted","timestamp":1756198844953,"user_tz":-180,"elapsed":41439,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["# Get interesting words to visualize\n","categories = {\n","    'emotions': ['love', 'hate', 'fear', 'joy', 'sorrow'],\n","    'time': ['time', 'day', 'night', 'hour', 'year'],\n","    'nature': ['sun', 'moon', 'star', 'sky', 'earth'],\n","    'people': ['man', 'woman', 'youth', 'friend', 'lord']\n","}\n","\n","# Collect words and their vectors\n","words_to_plot = []\n","vectors = []\n","colors = []\n","color_map = {'emotions': 'red', 'time': 'blue', 'nature': 'green', 'people': 'purple'}\n","\n","for category, word_list in categories.items():\n","    for word in word_list:\n","        if word in model.wv:\n","            words_to_plot.append(word)\n","            vectors.append(model.wv[word])\n","            colors.append(color_map[category])\n","\n","# Reduce to 3D using PCA\n","vectors_array = np.array(vectors)\n","pca = PCA(n_components=3, random_state=42)\n","vectors_3d = pca.fit_transform(vectors_array)\n","\n","print(f\"Visualizing {len(words_to_plot)} words in 3D space\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRr1HOzwmqVi","executionInfo":{"status":"aborted","timestamp":1756198844956,"user_tz":-180,"elapsed":41435,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["# Create interactive 3D plot\n","fig = go.Figure(data=[go.Scatter3d(\n","    x=vectors_3d[:, 0],\n","    y=vectors_3d[:, 1],\n","    z=vectors_3d[:, 2],\n","    mode='markers+text',\n","    text=words_to_plot,\n","    textposition='top center',\n","    marker=dict(\n","        size=8,\n","        color=colors,\n","        opacity=0.8,\n","        line=dict(width=1, color='white')\n","    ),\n","    hovertemplate='%{text}<extra></extra>'\n",")])\n","\n","fig.update_layout(\n","    title=\"Word Embeddings in 3D Space (Drag to Rotate!)\",\n","    scene=dict(\n","        xaxis_title=\"Dimension 1\",\n","        yaxis_title=\"Dimension 2\",\n","        zaxis_title=\"Dimension 3\",\n","        bgcolor='white'\n","    ),\n","    height=600,\n","    showlegend=False\n",")\n","\n","# Add legend manually\n","for category, color in color_map.items():\n","    fig.add_trace(go.Scatter3d(\n","        x=[None], y=[None], z=[None],\n","        mode='markers',\n","        marker=dict(size=10, color=color),\n","        name=category.capitalize(),\n","        showlegend=True\n","    ))\n","\n","fig.show()\n","\n","print(\"üéØ Notice how similar words cluster together!\")"]},{"cell_type":"markdown","metadata":{"id":"95hOZQ8PmqVj"},"source":["## Part 6: Word Arithmetic - The Magic of Vectors!\n","\n","With vectors, we can do math on words!\n","\n","Famous example: **king - man + woman = queen**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rS7L77yXmqVj","executionInfo":{"status":"aborted","timestamp":1756198844959,"user_tz":-180,"elapsed":41431,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["def word_arithmetic(positive_words, negative_words, model, top_n=5):\n","    \"\"\"\n","    Perform word arithmetic.\n","    Result = sum(positive_words) - sum(negative_words)\n","    \"\"\"\n","    # Check all words exist\n","    all_words = positive_words + negative_words\n","    for word in all_words:\n","        if word not in model.wv:\n","            print(f\"Word '{word}' not in vocabulary!\")\n","            return []\n","\n","    # Do the arithmetic\n","    result = model.wv.most_similar(\n","        positive=positive_words,\n","        negative=negative_words,\n","        topn=top_n\n","    )\n","\n","    return result\n","\n","# Try some word math with words from sonnets!\n","print(\"Word Arithmetic Examples:\")\n","print(\"=\"*40)\n","\n","# Example 1 - use common words from sonnets\n","print(\"\\n1. love - hate + beauty = ?\")\n","if all(w in model.wv for w in ['love', 'hate', 'beauty']):\n","    result = word_arithmetic(['love', 'beauty'], ['hate'], model, top_n=3)\n","    for word, score in result:\n","        print(f\"   ‚Üí {word} ({score:.2f})\")\n","else:\n","    print(\"   Some words not in vocabulary\")\n","\n","# Example 2\n","print(\"\\n2. day - night + sun = ?\")\n","if all(w in model.wv for w in ['day', 'night', 'sun']):\n","    result = word_arithmetic(['day', 'sun'], ['night'], model, top_n=3)\n","    for word, score in result:\n","        print(f\"   ‚Üí {word} ({score:.2f})\")\n","else:\n","    print(\"   Some words not in vocabulary\")\n","\n","# Example 3 - using words more likely to be in sonnets\n","print(\"\\n3. youth - old + beauty = ?\")\n","if all(w in model.wv for w in ['youth', 'old', 'beauty']):\n","    result = word_arithmetic(['youth', 'beauty'], ['old'], model, top_n=3)\n","    for word, score in result:\n","        print(f\"   ‚Üí {word} ({score:.2f})\")\n","else:\n","    print(\"   Some words not in vocabulary\")"]},{"cell_type":"markdown","metadata":{"id":"gWQzcNM-mqVk"},"source":["## Part 7: Visualizing Word Relationships\n","\n","Let's see how word vectors capture relationships!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJhCBkBXmqVk","executionInfo":{"status":"aborted","timestamp":1756198844964,"user_tz":-180,"elapsed":41430,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["# Create a word similarity matrix\n","selected_words = ['love', 'hate', 'time', 'beauty', 'death', 'life',\n","                  'youth', 'age', 'sun', 'moon', 'day', 'night']\n","\n","# Filter to words that exist\n","words_in_model = [w for w in selected_words if w in model.wv]\n","\n","# Build similarity matrix\n","n = len(words_in_model)\n","similarity_matrix = np.zeros((n, n))\n","\n","for i, word1 in enumerate(words_in_model):\n","    for j, word2 in enumerate(words_in_model):\n","        if i == j:\n","            similarity_matrix[i, j] = 1.0\n","        else:\n","            similarity_matrix[i, j] = model.wv.similarity(word1, word2)\n","\n","# Create heatmap\n","fig = go.Figure(data=go.Heatmap(\n","    z=similarity_matrix,\n","    x=words_in_model,\n","    y=words_in_model,\n","    colorscale='RdBu',\n","    zmid=0,\n","    text=np.round(similarity_matrix, 2),\n","    texttemplate='%{text}',\n","    textfont={\"size\": 8},\n","    colorbar=dict(title=\"Similarity\")\n","))\n","\n","fig.update_layout(\n","    title=\"Word Similarity Matrix (Red = Similar, Blue = Different)\",\n","    height=500,\n","    width=600,\n","    xaxis_title=\"Word\",\n","    yaxis_title=\"Word\"\n",")\n","\n","fig.show()\n","\n","print(\"üéØ Notice the patterns:\")\n","print(\"  - Opposites (love/hate, day/night) have low similarity\")\n","print(\"  - Related concepts (sun/day, moon/night) have high similarity\")"]},{"cell_type":"markdown","metadata":{"id":"sit2MhXEmqVk"},"source":["## Part 8: Using Embeddings for Next Word Prediction\n","\n","How do embeddings help with predicting the next word?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h84k1TIImqVk","executionInfo":{"status":"aborted","timestamp":1756198845041,"user_tz":-180,"elapsed":41500,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["def predict_next_word_with_embeddings(context_words, model, top_n=5):\n","    \"\"\"\n","    Predict next word based on context similarity.\n","    \"\"\"\n","    # Check if context words exist\n","    valid_words = [w for w in context_words if w in model.wv]\n","\n","    if not valid_words:\n","        print(\"No valid context words found!\")\n","        return []\n","\n","    # Get average vector of context\n","    context_vector = np.mean([model.wv[w] for w in valid_words], axis=0)\n","\n","    # Find most similar words to context\n","    similar_words = model.wv.similar_by_vector(context_vector, topn=top_n+len(valid_words))\n","\n","    # Filter out the context words themselves\n","    predictions = [(w, s) for w, s in similar_words if w not in valid_words][:top_n]\n","\n","    return predictions\n","\n","# Test prediction\n","print(\"Predicting next word using embeddings:\")\n","print(\"=\"*40)\n","\n","contexts = [\n","    ['the', 'beautiful'],\n","    ['love', 'and'],\n","    ['in', 'the', 'dark']\n","]\n","\n","for context in contexts:\n","    print(f\"\\nContext: {' '.join(context)} ___\")\n","    predictions = predict_next_word_with_embeddings(context, model)\n","    print(\"Predictions:\")\n","    for word, score in predictions:\n","        bar = '‚ñà' * int(score * 10)\n","        print(f\"  {word:10} {bar} {score:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"w9r8ZIR2mqVl"},"source":["## Part 9: Interactive Embedding Explorer\n","\n","Explore word relationships interactively!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Us8uhxRmqVl","executionInfo":{"status":"aborted","timestamp":1756198845048,"user_tz":-180,"elapsed":41501,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["def explore_word(word, model):\n","    \"\"\"\n","    Interactive word exploration.\n","    \"\"\"\n","    if word not in model.wv:\n","        print(f\"‚ùå Word '{word}' not found in vocabulary!\")\n","        print(\"Try common words like: love, time, beauty, death, life\")\n","        return\n","\n","    print(f\"\\nüîç Exploring: '{word}'\")\n","    print(\"=\"*50)\n","\n","    # Vector info\n","    vector = model.wv[word]\n","    print(f\"\\nüìä Vector Statistics:\")\n","    print(f\"  Dimensions: {len(vector)}\")\n","    print(f\"  Mean: {np.mean(vector):.3f}\")\n","    print(f\"  Std: {np.std(vector):.3f}\")\n","    print(f\"  Range: [{np.min(vector):.3f}, {np.max(vector):.3f}]\")\n","\n","    # Similar words\n","    print(f\"\\nü§ù Most Similar Words:\")\n","    similar = model.wv.most_similar(word, topn=5)\n","    for sim_word, score in similar:\n","        bar = '‚ñà' * int(score * 10)\n","        print(f\"  {sim_word:12} {bar} {score:.2f}\")\n","\n","    # Opposite words (least similar)\n","    print(f\"\\nüîÑ Most Different Words:\")\n","    all_words = list(model.wv.index_to_key)[:100]  # Check top 100 words\n","    similarities = [(w, model.wv.similarity(word, w)) for w in all_words if w != word]\n","    similarities.sort(key=lambda x: x[1])\n","\n","    for opp_word, score in similarities[:5]:\n","        bar = '‚ñà' * max(0, int((1 + score) * 5))  # Adjust for negative scores\n","        print(f\"  {opp_word:12} {bar} {score:.2f}\")\n","\n","# Try it!\n","explore_word('love', model)\n","print(\"\\n\" + \"=\"*50)\n","explore_word('death', model)"]},{"cell_type":"markdown","metadata":{"id":"z_v6BQ2NmqVl"},"source":["## Summary: What We Learned About Word Embeddings\n","\n","### Key Concepts:\n","1. **Words as Vectors**: Each word becomes a list of numbers\n","2. **Similarity**: Similar words have similar vectors\n","3. **Context Matters**: Words learn meaning from their neighbors\n","4. **Word Math**: We can add and subtract word meanings!\n","\n","### Why Embeddings are Better than Counting:\n","\n","| Aspect | N-grams (Counting) | Word Embeddings |\n","|--------|-------------------|------------------|\n","| **Similarity** | ‚ùå Can't measure | ‚úÖ Built-in |\n","| **Size** | Huge sparse matrices | Small dense vectors |\n","| **Generalization** | Only exact matches | Finds similar words |\n","| **Relationships** | None | Captures analogies |\n","\n","### Applications:\n","- üîç Search engines (find related terms)\n","- üí¨ Chatbots (understand user intent)\n","- üåç Translation (match concepts across languages)\n","- üìù Text generation (better predictions)\n","\n","### Next Steps:\n","- **Notebook 3**: Use embeddings in a neural network\n","- **Notebook 4**: Compare all methods for next-word prediction"]},{"cell_type":"markdown","metadata":{"id":"0amFypaumqVm"},"source":["## Bonus: Create Your Own Word Analogy!\n","\n","Try creating your own word equations!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zb7HkgC4mqVm","executionInfo":{"status":"aborted","timestamp":1756198845050,"user_tz":-180,"elapsed":41499,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":["def interactive_word_math():\n","    \"\"\"\n","    Interactive word arithmetic playground.\n","    \"\"\"\n","    print(\"üßÆ Word Math Playground\")\n","    print(\"=\"*40)\n","    print(\"Formula: result = positive_words - negative_words\")\n","    print(\"Example: king - man + woman = queen\\n\")\n","\n","    # Some examples to try\n","    examples = [\n","        ([\"summer\", \"hot\"], [\"winter\"], \"What's hot in summer but not in winter?\"),\n","        ([\"paris\", \"france\"], [\"london\"], \"Paris is to France as London is to?\"),\n","        ([\"good\", \"best\"], [\"bad\"], \"Good is to best as bad is to?\")\n","    ]\n","\n","    for pos, neg, hint in examples:\n","        print(f\"\\n{hint}\")\n","        print(f\"Calculating: {' + '.join(pos)} - {' - '.join(neg)}\")\n","\n","        # Check if words exist\n","        all_words = pos + neg\n","        valid = all([w in model.wv for w in all_words])\n","\n","        if valid:\n","            result = word_arithmetic(pos, neg, model, top_n=3)\n","            print(\"Results:\")\n","            for word, score in result:\n","                print(f\"  ‚Üí {word} ({score:.2f})\")\n","        else:\n","            missing = [w for w in all_words if w not in model.wv]\n","            print(f\"  ‚ùå Missing words: {missing}\")\n","\n","interactive_word_math()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r82R_jFdmqVm","executionInfo":{"status":"aborted","timestamp":1756198845059,"user_tz":-180,"elapsed":41507,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cG9j0Z6ImqVm","executionInfo":{"status":"aborted","timestamp":1756198845064,"user_tz":-180,"elapsed":41511,"user":{"displayName":"Victor Vladkov","userId":"00620192427858643134"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}