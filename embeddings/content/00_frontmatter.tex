% Frontmatter: Title Slide and Overview

% Title Slide
\begin{frame}
\titlepage
\end{frame}

% Table of Contents
\begin{frame}{Outline}
\tableofcontents
\end{frame}

% Learning Objectives
\begin{frame}{What You Will Learn}
\textbf{By the end of this presentation, you will understand:}

\begin{enumerate}
\item \highlight{Representation Problem}: Why computers need numerical representations of words
\item \highlight{Evolution of Embeddings}: From one-hot to contextual representations
\item \highlight{Mathematical Foundations}: The theory behind word embeddings
\item \highlight{Vector Operations}: How semantic relationships emerge from vectors
\item \highlight{High-Dimensional Challenges}: The curse of dimensionality
\item \highlight{Training Dynamics}: How embeddings learn meaningful representations
\item \highlight{Skip-gram Architecture}: Deep dive into Word2Vec training
\end{enumerate}

\vspace{0.5em}
\begin{center}
\colorbox{lightblue}{
\parbox{0.8\textwidth}{
\centering
\textbf{Key Insight:} Words are not isolated symbols but points in a continuous semantic space
}
}
\end{center}
\end{frame}