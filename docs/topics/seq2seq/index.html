<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Sequence-to-Sequence | NLP Course</title>
<link rel=stylesheet href=https://digital-ai-finance.github.io/Natural-Language-Processing/css/main.css></head><body><nav class=sidebar><div class=sidebar-header><a href=https://digital-ai-finance.github.io/Natural-Language-Processing/>NLP Course</a></div><ul class=sidebar-nav><li><a href=https://digital-ai-finance.github.io/Natural-Language-Processing/topics/>Topics</a></li><li><a href=https://digital-ai-finance.github.io/Natural-Language-Processing/modules/>Modules</a></li></ul></nav><main class=content><article class=page><h1>Sequence-to-Sequence</h1><p><strong>Encoder-Decoder Architecture</strong></p><p><span class=badge>38 SLIDES</span>
<span class="badge part-2">Part 2: Core Architectures</span></p><h2 id=overview>Overview</h2><p>Map sequences to sequences. The foundation of machine translation and summarization.</p><h2 id=learning-objectives>Learning Objectives</h2><ul><li>Build encoder-decoder architectures</li><li>Implement attention mechanisms</li><li>Apply teacher forcing during training</li><li>Use beam search for decoding</li></ul><h2 id=key-topics>Key Topics</h2><div class=topics-grid><div class=topic-item>Encoder-decoder</div><div class=topic-item>Attention mechanism</div><div class=topic-item>Teacher forcing</div><div class=topic-item>Beam search</div></div><h2 id=key-visualizations>Key Visualizations</h2><div class=chart-grid><div class=chart-item><img src=/Natural-Language-Processing/charts/week4_encoder_decoder_flow.png alt=week4_encoder_decoder_flow>
<span>Week4 Encoder Decoder Flow</span></div><div class=chart-item><img src=/Natural-Language-Processing/charts/week4_attention_heatmap.png alt=week4_attention_heatmap>
<span>Week4 Attention Heatmap</span></div><div class=chart-item><img src=/Natural-Language-Processing/charts/week4_beam_search_tree.png alt=week4_beam_search_tree>
<span>Week4 Beam Search Tree</span></div><div class=chart-item><img src=/Natural-Language-Processing/charts/week4_seq2seq_architecture_minimalist.png alt=week4_seq2seq_architecture_minimalist>
<span>Week4 Seq2Seq Architecture Minimalist</span></div></div><h2 id=resources>Resources</h2><div class=resource-buttons><p><a href=/Natural-Language-Processing/slides/seq2seq.pdf class=btn>View Slides (PDF)</a>
<a href=/Natural-Language-Processing/notebooks/seq2seq.ipynb class="btn secondary">Lab Notebook</a>
<a href=/Natural-Language-Processing/charts/ class="btn secondary">Chart Gallery</a></p></div><div class=nav-cards><a href=/Natural-Language-Processing/topics/rnn-lstm/ class="nav-card prev"><span class=nav-label>Previous</span>
<span class=nav-title>RNN & LSTM Networks</span>
</a><a href=/Natural-Language-Processing/topics/transformers/ class="nav-card next"><span class=nav-label>Next</span>
<span class=nav-title>Transformer Architecture</span></a></div></article></main></body></html>