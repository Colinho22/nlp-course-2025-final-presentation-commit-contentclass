{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Comparing Reasoning Approaches\n",
    "\n",
    "**NLP Final Lecture - Live Demo**\n",
    "\n",
    "This notebook demonstrates the difference between:\n",
    "1. Direct answering (no reasoning)\n",
    "2. Chain-of-thought prompting\n",
    "3. Structured reasoning traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Problem\n",
    "\n",
    "A classic multi-step math problem that requires reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"\"\"A store has 312 apples. They sell 1/4 of them in the morning and 1/3 of the \n",
    "remaining apples in the afternoon. How many apples are left at the end of the day?\"\"\"\n",
    "\n",
    "print(\"Problem:\")\n",
    "print(problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Direct Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_answer(problem):\n",
    "    \"\"\"Ask for direct answer without reasoning.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Answer with just the number, nothing else.\"},\n",
    "            {\"role\": \"user\", \"content\": problem}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "direct_result = direct_answer(problem)\n",
    "print(f\"Direct answer: {direct_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Chain-of-Thought (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cot_zero_shot(problem):\n",
    "    \"\"\"Use zero-shot chain-of-thought prompting.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"{problem}\\n\\nLet's think step by step.\"}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "cot_result = cot_zero_shot(problem)\n",
    "print(\"Chain-of-Thought (Zero-Shot):\")\n",
    "print(cot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: Structured Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structured_reasoning(problem):\n",
    "    \"\"\"Use structured reasoning format.\"\"\"\n",
    "    system_prompt = \"\"\"You are a careful problem solver. For each problem:\n",
    "1. First, identify the given information\n",
    "2. Then, break down the problem into steps\n",
    "3. Solve each step showing your calculations\n",
    "4. Verify your answer makes sense\n",
    "5. State the final answer clearly\n",
    "\n",
    "Use <thinking>...</thinking> tags for your reasoning and <answer>...</answer> for the final answer.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": problem}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "structured_result = structured_reasoning(problem)\n",
    "print(\"Structured Reasoning:\")\n",
    "print(structured_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification: What's the Correct Answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's verify manually:\n",
    "initial = 312\n",
    "after_morning = initial - (initial // 4)  # Sell 1/4\n",
    "after_afternoon = after_morning - (after_morning // 3)  # Sell 1/3 of remaining\n",
    "\n",
    "print(\"Manual verification:\")\n",
    "print(f\"Initial apples: {initial}\")\n",
    "print(f\"Sold in morning (1/4): {initial // 4}\")\n",
    "print(f\"After morning: {after_morning}\")\n",
    "print(f\"Sold in afternoon (1/3 of remaining): {after_morning // 3}\")\n",
    "print(f\"Final answer: {after_afternoon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harder Problem: Self-Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_problem = \"\"\"In a room of 23 people, what is the probability that at least two people \n",
    "share the same birthday? Assume 365 days in a year and uniform birthday distribution.\"\"\"\n",
    "\n",
    "print(\"Harder problem:\")\n",
    "print(hard_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_consistency(problem, n_samples=5):\n",
    "    \"\"\"Generate multiple reasoning chains and take majority vote.\"\"\"\n",
    "    answers = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": f\"{problem}\\n\\nThink step by step and give your final answer as a percentage.\"}\n",
    "            ],\n",
    "            temperature=0.7  # Higher temperature for diversity\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content\n",
    "        # Extract percentage (simplified extraction)\n",
    "        import re\n",
    "        percentages = re.findall(r'(\\d+\\.?\\d*)%', result)\n",
    "        if percentages:\n",
    "            answers.append(float(percentages[-1]))  # Take last mentioned percentage\n",
    "        print(f\"Sample {i+1}: {percentages[-1] if percentages else 'N/A'}%\")\n",
    "    \n",
    "    if answers:\n",
    "        avg = sum(answers) / len(answers)\n",
    "        print(f\"\\nAverage across samples: {avg:.1f}%\")\n",
    "        print(f\"(True answer is approximately 50.7%)\")\n",
    "    \n",
    "    return answers\n",
    "\n",
    "print(\"Self-consistency with 5 samples:\\n\")\n",
    "results = self_consistency(hard_problem, n_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Chain-of-thought improves accuracy**: Just adding \"Let's think step by step\" helps\n",
    "2. **Structure helps verification**: Explicit reasoning traces can be checked\n",
    "3. **Self-consistency reduces errors**: Multiple samples with voting\n",
    "4. **Test-time compute**: More reasoning tokens = better results (up to a point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Simulating o1-style Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def o1_style_reasoning(problem):\n",
    "    \"\"\"Simulate extended reasoning like o1 models.\"\"\"\n",
    "    system_prompt = \"\"\"You are a careful mathematical reasoner. Before answering:\n",
    "\n",
    "1. Consider multiple approaches to the problem\n",
    "2. Check if your approach is correct before calculating\n",
    "3. After getting an answer, verify it makes sense\n",
    "4. If you notice an error, backtrack and try again\n",
    "\n",
    "Show your complete reasoning process, including any corrections.\n",
    "Use extensive step-by-step reasoning.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": problem}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=2000  # Allow extended reasoning\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "olympiad_problem = \"\"\"Find all positive integers n such that n^2 + 1 is divisible by n + 1.\"\"\"\n",
    "\n",
    "print(\"Olympiad-style problem:\")\n",
    "print(olympiad_problem)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(o1_style_reasoning(olympiad_problem))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
