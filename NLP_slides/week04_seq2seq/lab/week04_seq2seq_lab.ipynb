{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Sequence-to-Sequence Models - Interactive Lab\n",
    "\n",
    "## Learning Objectives\n",
    "- Build a basic encoder-decoder model from scratch\n",
    "- Visualize the information bottleneck problem\n",
    "- Implement attention mechanism step by step\n",
    "- See seq2seq models in action with translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Helper function to create clean visualizations\n",
    "def plot_matrix(matrix, xlabel='', ylabel='', title='', cmap='Blues', figsize=(8, 6)):\n",
    "    \"\"\"Helper function to plot matrices consistently.\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(matrix, annot=True, fmt='.2f', cmap=cmap, cbar=True, \n",
    "                square=True, linewidths=1, linecolor='gray')\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Setup complete! Let's explore sequence-to-sequence models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Variable-Length Challenge\n",
    "\n",
    "Let's start by understanding why translation is hard for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation examples showing length mismatch\n",
    "translations = [\n",
    "    (\"I love you\", \"Je t'aime\", \"French\"),\n",
    "    (\"I love you\", \"Ich liebe dich\", \"German\"),\n",
    "    (\"I love you\", \"Aishiteru\", \"Japanese\"),\n",
    "    (\"I love you\", \"Te amo\", \"Spanish\"),\n",
    "    (\"I love you\", \"Wo ai ni\", \"Chinese\"),\n",
    "]\n",
    "\n",
    "# Visualize length differences\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar chart of word counts\n",
    "languages = [t[2] for t in translations]\n",
    "english_lengths = [len(t[0].split()) for t in translations]\n",
    "target_lengths = [len(t[1].split()) for t in translations]\n",
    "\n",
    "x = np.arange(len(languages))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, english_lengths, width, label='English', color='#4ECDC4')\n",
    "ax1.bar(x + width/2, target_lengths, width, label='Target Language', color='#FF6B6B')\n",
    "ax1.set_xlabel('Language')\n",
    "ax1.set_ylabel('Number of Words')\n",
    "ax1.set_title('Word Count Comparison: \"I love you\"')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(languages)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot showing no correlation\n",
    "np.random.seed(42)\n",
    "sample_sentences = [\n",
    "    (3, 2), (5, 7), (10, 8), (7, 12), (15, 10),\n",
    "    (4, 6), (8, 5), (12, 14), (6, 9), (20, 15)\n",
    "]\n",
    "eng_lens = [s[0] for s in sample_sentences]\n",
    "fr_lens = [s[1] for s in sample_sentences]\n",
    "\n",
    "ax2.scatter(eng_lens, fr_lens, s=100, alpha=0.6, color='#FF6B6B')\n",
    "ax2.plot([0, 20], [0, 20], 'k--', alpha=0.3, label='1:1 mapping')\n",
    "ax2.set_xlabel('English Sentence Length (words)')\n",
    "ax2.set_ylabel('French Sentence Length (words)')\n",
    "ax2.set_title('No Fixed Length Relationship')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight: Different languages use different numbers of words!\")\n",
    "print(\"This means we can't use a simple one-to-one neural network mapping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building an Encoder-Decoder\n",
    "\n",
    "Let's build a simple encoder-decoder model to understand how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoder:\n",
    "    \"\"\"A simplified encoder that processes input sequences.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size=4):\n",
    "        self.hidden_size = hidden_size\n",
    "        # Simulate word embeddings\n",
    "        self.embeddings = {\n",
    "            'the': np.array([0.1, 0.2, 0.3, 0.1]),\n",
    "            'cat': np.array([0.8, 0.1, 0.05, 0.05]),\n",
    "            'sat': np.array([0.2, 0.7, 0.05, 0.05]),\n",
    "            'on': np.array([0.1, 0.1, 0.4, 0.4]),\n",
    "            'mat': np.array([0.3, 0.2, 0.2, 0.3]),\n",
    "        }\n",
    "    \n",
    "    def encode(self, sentence: List[str]) -> np.ndarray:\n",
    "        \"\"\"Encode a sentence into a fixed-size vector.\"\"\"\n",
    "        # Initialize hidden state\n",
    "        hidden = np.zeros(self.hidden_size)\n",
    "        \n",
    "        # Process each word (simplified RNN)\n",
    "        states = []\n",
    "        for word in sentence:\n",
    "            if word in self.embeddings:\n",
    "                # Simplified RNN update\n",
    "                hidden = 0.5 * hidden + 0.5 * self.embeddings[word]\n",
    "                states.append(hidden.copy())\n",
    "        \n",
    "        return hidden, states\n",
    "\n",
    "class SimpleDecoder:\n",
    "    \"\"\"A simplified decoder that generates output sequences.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size=4):\n",
    "        self.hidden_size = hidden_size\n",
    "        # Simulate output vocabulary\n",
    "        self.vocab = ['le', 'chat', 'sur', 'tapis', 'est', 'assis']\n",
    "    \n",
    "    def decode(self, context: np.ndarray, max_length: int = 5) -> List[str]:\n",
    "        \"\"\"Decode from context vector to output sequence.\"\"\"\n",
    "        output = []\n",
    "        hidden = context.copy()\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            # Simplified: choose word based on highest hidden value\n",
    "            idx = np.argmax(hidden) % len(self.vocab)\n",
    "            output.append(self.vocab[idx])\n",
    "            # Update hidden state (simplified)\n",
    "            hidden = hidden * 0.9 + np.random.randn(self.hidden_size) * 0.1\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Test the encoder-decoder\n",
    "encoder = SimpleEncoder()\n",
    "decoder = SimpleDecoder()\n",
    "\n",
    "# Encode a sentence\n",
    "input_sentence = ['the', 'cat', 'sat', 'on', 'the', 'mat']\n",
    "context_vector, encoder_states = encoder.encode(input_sentence)\n",
    "\n",
    "# Decode to French\n",
    "output_sentence = decoder.decode(context_vector)\n",
    "\n",
    "print(\"Input (English):\", ' '.join(input_sentence))\n",
    "print(\"Context Vector:\", context_vector)\n",
    "print(\"Output (French):\", ' '.join(output_sentence))\n",
    "\n",
    "# Visualize the encoding process\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot encoder states\n",
    "plt.subplot(1, 2, 1)\n",
    "states_matrix = np.array(encoder_states).T\n",
    "plt.imshow(states_matrix, aspect='auto', cmap='RdBu_r')\n",
    "plt.colorbar(label='Activation')\n",
    "plt.xlabel('Time Steps (Words)')\n",
    "plt.ylabel('Hidden Units')\n",
    "plt.title('Encoder Hidden States Over Time')\n",
    "plt.xticks(range(len(input_sentence)), input_sentence, rotation=45)\n",
    "\n",
    "# Plot final context vector\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(len(context_vector)), context_vector, color='#4ECDC4')\n",
    "plt.xlabel('Hidden Dimension')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Final Context Vector (Bottleneck)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The Information Bottleneck Problem\n",
    "\n",
    "Let's visualize why compressing everything into a single vector is problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_information_loss(sentence_length: int, context_size: int = 256) -> float:\n",
    "    \"\"\"Estimate information loss when compressing a sentence.\"\"\"\n",
    "    # Assume each word contains ~10 bits of information\n",
    "    bits_per_word = 10\n",
    "    total_information = sentence_length * bits_per_word\n",
    "    \n",
    "    # Context vector capacity (assuming each dimension stores 1 bit effectively)\n",
    "    context_capacity = context_size\n",
    "    \n",
    "    # Calculate loss\n",
    "    if total_information <= context_capacity:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return (total_information - context_capacity) / total_information\n",
    "\n",
    "# Test with different sentence lengths\n",
    "sentence_lengths = range(1, 101, 5)\n",
    "losses_256 = [measure_information_loss(l, 256) for l in sentence_lengths]\n",
    "losses_512 = [measure_information_loss(l, 512) for l in sentence_lengths]\n",
    "losses_1024 = [measure_information_loss(l, 1024) for l in sentence_lengths]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(sentence_lengths, losses_256, label='256-dim context', linewidth=2)\n",
    "plt.plot(sentence_lengths, losses_512, label='512-dim context', linewidth=2)\n",
    "plt.plot(sentence_lengths, losses_1024, label='1024-dim context', linewidth=2)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='50% loss threshold')\n",
    "plt.xlabel('Sentence Length (words)')\n",
    "plt.ylabel('Information Loss (%)')\n",
    "plt.title('Information Bottleneck Problem')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Demonstrate with actual compression\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Compress sentences of different lengths\n",
    "test_sentences = [\n",
    "    \"Hello world\",\n",
    "    \"The quick brown fox jumps\",\n",
    "    \"The International Conference on Machine Learning accepted our paper\",\n",
    "    \"The International Conference on Machine Learning, which is one of the premier venues for presenting research in machine learning and attracts submissions from researchers around the world\"\n",
    "]\n",
    "\n",
    "lengths = [len(s.split()) for s in test_sentences]\n",
    "context_dims = 8  # Use small dimension for visualization\n",
    "\n",
    "contexts = []\n",
    "for sent in test_sentences:\n",
    "    # Simulate compression: more words = more averaged out\n",
    "    words = sent.split()\n",
    "    context = np.random.randn(context_dims)\n",
    "    # Averaging effect\n",
    "    context = context / np.sqrt(len(words))\n",
    "    contexts.append(context)\n",
    "\n",
    "# Plot contexts as heatmap\n",
    "contexts_matrix = np.array(contexts)\n",
    "im = plt.imshow(contexts_matrix.T, aspect='auto', cmap='RdBu_r')\n",
    "plt.colorbar(im, label='Value')\n",
    "plt.xlabel('Sentence')\n",
    "plt.ylabel('Context Dimension')\n",
    "plt.title('Context Vectors Get More \"Averaged Out\" with Length')\n",
    "plt.xticks(range(len(lengths)), [f\"{l} words\" for l in lengths])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight: Longer sentences lose more information when compressed!\")\n",
    "print(\"This is why vanilla seq2seq models fail on long sentences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Introducing Attention\n",
    "\n",
    "Now let's implement a simple attention mechanism to solve the bottleneck problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModule:\n",
    "    \"\"\"Simple attention mechanism.\"\"\"\n",
    "    \n",
    "    def compute_attention(self, \n",
    "                         query: np.ndarray, \n",
    "                         keys: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Compute attention weights and context vector.\n",
    "        \n",
    "        Args:\n",
    "            query: Current decoder state (hidden_size,)\n",
    "            keys: List of encoder states [(hidden_size,), ...]\n",
    "            \n",
    "        Returns:\n",
    "            attention_weights: Attention distribution over keys\n",
    "            context: Weighted sum of keys\n",
    "        \"\"\"\n",
    "        # Compute similarity scores (dot product attention)\n",
    "        scores = []\n",
    "        for key in keys:\n",
    "            score = np.dot(query, key)\n",
    "            scores.append(score)\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        exp_scores = np.exp(scores - np.max(scores))  # Numerical stability\n",
    "        attention_weights = exp_scores / np.sum(exp_scores)\n",
    "        \n",
    "        # Compute weighted sum (context vector)\n",
    "        context = np.zeros_like(keys[0])\n",
    "        for weight, key in zip(attention_weights, keys):\n",
    "            context += weight * key\n",
    "        \n",
    "        return attention_weights, context\n",
    "\n",
    "# Demonstrate attention on our example\n",
    "attention = AttentionModule()\n",
    "\n",
    "# Use encoder states from before\n",
    "encoder = SimpleEncoder()\n",
    "input_sentence = ['the', 'cat', 'sat', 'on', 'the', 'mat']\n",
    "_, encoder_states = encoder.encode(input_sentence)\n",
    "\n",
    "# Simulate different decoder states focusing on different parts\n",
    "decoder_queries = [\n",
    "    np.array([0.8, 0.1, 0.05, 0.05]),  # Focus on \"cat\"\n",
    "    np.array([0.2, 0.7, 0.05, 0.05]),  # Focus on \"sat\"\n",
    "    np.array([0.3, 0.2, 0.2, 0.3]),    # Focus on \"mat\"\n",
    "]\n",
    "\n",
    "query_labels = ['Generating \"chat\" (cat)', 'Generating \"assis\" (sat)', 'Generating \"tapis\" (mat)']\n",
    "\n",
    "# Compute attention for each query\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, (query, label) in enumerate(zip(decoder_queries, query_labels)):\n",
    "    weights, context = attention.compute_attention(query, encoder_states)\n",
    "    \n",
    "    # Plot attention weights\n",
    "    ax = axes[idx]\n",
    "    ax.bar(range(len(input_sentence)), weights, color='#FF6B6B', alpha=0.7)\n",
    "    ax.set_xlabel('Source Words')\n",
    "    ax.set_ylabel('Attention Weight')\n",
    "    ax.set_title(label)\n",
    "    ax.set_xticks(range(len(input_sentence)))\n",
    "    ax.set_xticklabels(input_sentence, rotation=45)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight the most attended word\n",
    "    max_idx = np.argmax(weights)\n",
    "    ax.bar(max_idx, weights[max_idx], color='#FF6B6B')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight: Attention allows the decoder to focus on relevant source words!\")\n",
    "print(\"This solves the information bottleneck problem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Visualizing Attention in Translation\n",
    "\n",
    "Let's create a complete attention visualization for a translation example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic attention pattern for translation\n",
    "source_sentence = \"The black cat sat on the mat\"\n",
    "target_sentence = \"Le chat noir s'est assis sur le tapis\"\n",
    "\n",
    "source_words = source_sentence.split()\n",
    "target_words = target_sentence.split()\n",
    "\n",
    "# Define attention alignment (which source words each target word attends to)\n",
    "# This is based on linguistic alignment\n",
    "attention_matrix = np.zeros((len(target_words), len(source_words)))\n",
    "\n",
    "# Manual alignment based on translation\n",
    "alignments = [\n",
    "    (0, 0),   # Le -> The\n",
    "    (1, 2),   # chat -> cat\n",
    "    (2, 1),   # noir -> black\n",
    "    (3, 3),   # s'est -> sat\n",
    "    (4, 3),   # assis -> sat\n",
    "    (5, 4),   # sur -> on\n",
    "    (6, 5),   # le -> the\n",
    "    (7, 6),   # tapis -> mat\n",
    "]\n",
    "\n",
    "# Create attention weights with some noise\n",
    "np.random.seed(42)\n",
    "for tgt_idx in range(len(target_words)):\n",
    "    # Add small random weights everywhere\n",
    "    attention_matrix[tgt_idx, :] = np.random.random(len(source_words)) * 0.1\n",
    "    \n",
    "    # Add strong weight for aligned words\n",
    "    for align_tgt, align_src in alignments:\n",
    "        if align_tgt == tgt_idx:\n",
    "            attention_matrix[tgt_idx, align_src] += 0.7\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    attention_matrix[tgt_idx, :] /= attention_matrix[tgt_idx, :].sum()\n",
    "\n",
    "# Create attention heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(attention_matrix, \n",
    "            xticklabels=source_words,\n",
    "            yticklabels=target_words,\n",
    "            cmap='Blues',\n",
    "            cbar_kws={'label': 'Attention Weight'},\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray',\n",
    "            square=True)\n",
    "\n",
    "plt.xlabel('Source (English)', fontsize=12)\n",
    "plt.ylabel('Target (French)', fontsize=12)\n",
    "plt.title('Attention Weights in Translation', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add text annotations for high attention values\n",
    "for i in range(len(target_words)):\n",
    "    for j in range(len(source_words)):\n",
    "        if attention_matrix[i, j] > 0.3:\n",
    "            plt.text(j + 0.5, i + 0.5, f'{attention_matrix[i, j]:.2f}',\n",
    "                    ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how:\")\n",
    "print(\"1. 'chat' (cat) strongly attends to 'cat' in the source\")\n",
    "print(\"2. 'noir' (black) attends to 'black'\")\n",
    "print(\"3. Some target words attend to multiple source words (s'est assis -> sat)\")\n",
    "print(\"4. The attention pattern roughly follows diagonal alignment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Comparing Attention Types\n",
    "\n",
    "Let's compare different attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_attention(query, key):\n",
    "    \"\"\"Bahdanau attention (dot product).\"\"\"\n",
    "    return np.dot(query, key)\n",
    "\n",
    "def additive_attention(query, key, W1=None, W2=None, v=None):\n",
    "    \"\"\"Additive attention (Bahdanau style with learnable parameters).\"\"\"\n",
    "    # Simulate learned parameters\n",
    "    if W1 is None:\n",
    "        W1 = np.random.randn(4, 4) * 0.1\n",
    "    if W2 is None:\n",
    "        W2 = np.random.randn(4, 4) * 0.1\n",
    "    if v is None:\n",
    "        v = np.random.randn(4) * 0.1\n",
    "    \n",
    "    # Compute attention score\n",
    "    combined = np.tanh(W1 @ query + W2 @ key)\n",
    "    return np.dot(v, combined)\n",
    "\n",
    "def scaled_dot_product_attention(query, key):\n",
    "    \"\"\"Scaled dot product (used in Transformers).\"\"\"\n",
    "    d_k = len(key)\n",
    "    return np.dot(query, key) / np.sqrt(d_k)\n",
    "\n",
    "# Compare attention mechanisms\n",
    "query = np.array([0.5, 0.3, 0.1, 0.1])\n",
    "keys = [\n",
    "    np.array([0.1, 0.2, 0.3, 0.4]),\n",
    "    np.array([0.4, 0.3, 0.2, 0.1]),\n",
    "    np.array([0.5, 0.3, 0.1, 0.1]),  # Similar to query\n",
    "    np.array([0.2, 0.2, 0.3, 0.3]),\n",
    "]\n",
    "\n",
    "attention_types = [\n",
    "    ('Dot Product', [dot_product_attention(query, k) for k in keys]),\n",
    "    ('Scaled Dot Product', [scaled_dot_product_attention(query, k) for k in keys]),\n",
    "    ('Additive', [additive_attention(query, k) for k in keys]),\n",
    "]\n",
    "\n",
    "# Visualize different attention scores\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, (name, scores) in enumerate(attention_types):\n",
    "    # Convert to probabilities\n",
    "    scores = np.array(scores)\n",
    "    exp_scores = np.exp(scores - np.max(scores))\n",
    "    probs = exp_scores / np.sum(exp_scores)\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    bars = ax.bar(range(len(probs)), probs, color=['#FF6B6B', '#4ECDC4', '#95E77E', '#FAB563'])\n",
    "    ax.set_xlabel('Key Index')\n",
    "    ax.set_ylabel('Attention Weight')\n",
    "    ax.set_title(f'{name} Attention')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight the highest attention\n",
    "    max_idx = np.argmax(probs)\n",
    "    bars[max_idx].set_edgecolor('black')\n",
    "    bars[max_idx].set_linewidth(2)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, prob in zip(bars, probs):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{prob:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Observations:\")\n",
    "print(\"1. All attention types identify key 2 (similar to query) as important\")\n",
    "print(\"2. Scaled dot product prevents values from getting too large\")\n",
    "print(\"3. Additive attention can learn more complex patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Beam Search Visualization\n",
    "\n",
    "Let's visualize how beam search explores multiple translation paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate beam search for translation\n",
    "import networkx as nx\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "\n",
    "# Define beam search tree\n",
    "beam_tree = {\n",
    "    'START': [\n",
    "        ('Le', 0.8),\n",
    "        ('Un', 0.15),\n",
    "        ('La', 0.05)\n",
    "    ],\n",
    "    'Le': [\n",
    "        ('chat', 0.9),\n",
    "        ('chien', 0.08),\n",
    "        ('animal', 0.02)\n",
    "    ],\n",
    "    'Un': [\n",
    "        ('chat', 0.7),\n",
    "        ('animal', 0.3)\n",
    "    ],\n",
    "    'Le-chat': [\n",
    "        ('noir', 0.85),\n",
    "        ('blanc', 0.1),\n",
    "        ('est', 0.05)\n",
    "    ],\n",
    "    'Le-chien': [\n",
    "        ('noir', 0.6),\n",
    "        ('court', 0.4)\n",
    "    ],\n",
    "    'Un-chat': [\n",
    "        ('noir', 0.8),\n",
    "        ('dort', 0.2)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: Beam search tree\n",
    "ax1.set_xlim(-0.5, 3.5)\n",
    "ax1.set_ylim(-0.5, 4.5)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Beam Search Tree (beam_size=2)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Draw nodes and edges\n",
    "positions = {\n",
    "    'START': (0, 2),\n",
    "    'Le': (1, 3),\n",
    "    'Un': (1, 1),\n",
    "    'chat1': (2, 3.5),\n",
    "    'chien': (2, 2.5),\n",
    "    'chat2': (2, 1),\n",
    "    'noir1': (3, 3.5),\n",
    "    'noir2': (3, 2.5),\n",
    "}\n",
    "\n",
    "# Draw edges with probabilities\n",
    "edges = [\n",
    "    ('START', 'Le', 0.8, True),\n",
    "    ('START', 'Un', 0.15, True),\n",
    "    ('Le', 'chat1', 0.72, True),  # 0.8 * 0.9\n",
    "    ('Le', 'chien', 0.064, False),  # 0.8 * 0.08\n",
    "    ('Un', 'chat2', 0.105, True),  # 0.15 * 0.7\n",
    "    ('chat1', 'noir1', 0.612, True),  # 0.72 * 0.85\n",
    "    ('chat2', 'noir2', 0.084, False),  # 0.105 * 0.8\n",
    "]\n",
    "\n",
    "for start, end, prob, in_beam in edges:\n",
    "    start_pos = positions[start]\n",
    "    end_pos = positions[end]\n",
    "    \n",
    "    color = '#4ECDC4' if in_beam else '#E0E0E0'\n",
    "    width = 2 if in_beam else 1\n",
    "    alpha = 1.0 if in_beam else 0.4\n",
    "    \n",
    "    ax1.arrow(start_pos[0], start_pos[1], \n",
    "             end_pos[0] - start_pos[0] - 0.15, \n",
    "             end_pos[1] - start_pos[1],\n",
    "             head_width=0.08, head_length=0.1, \n",
    "             fc=color, ec=color, linewidth=width, alpha=alpha)\n",
    "    \n",
    "    # Add probability label\n",
    "    mid_x = (start_pos[0] + end_pos[0]) / 2\n",
    "    mid_y = (start_pos[1] + end_pos[1]) / 2\n",
    "    ax1.text(mid_x, mid_y + 0.1, f'{prob:.3f}', \n",
    "            fontsize=9, ha='center', \n",
    "            color='black' if in_beam else 'gray')\n",
    "\n",
    "# Draw nodes\n",
    "node_labels = {\n",
    "    'START': 'START',\n",
    "    'Le': 'Le',\n",
    "    'Un': 'Un',\n",
    "    'chat1': 'chat',\n",
    "    'chien': 'chien',\n",
    "    'chat2': 'chat',\n",
    "    'noir1': 'noir',\n",
    "    'noir2': 'noir',\n",
    "}\n",
    "\n",
    "for node, pos in positions.items():\n",
    "    # Check if node is in beam\n",
    "    in_beam = node in ['START', 'Le', 'Un', 'chat1', 'chat2', 'noir1']\n",
    "    \n",
    "    color = '#FF6B6B' if in_beam else '#E0E0E0'\n",
    "    \n",
    "    circle = plt.Circle(pos, 0.15, color=color, alpha=0.8 if in_beam else 0.4)\n",
    "    ax1.add_patch(circle)\n",
    "    ax1.text(pos[0], pos[1], node_labels[node], \n",
    "            ha='center', va='center', fontsize=10, \n",
    "            fontweight='bold' if in_beam else 'normal',\n",
    "            color='white' if in_beam else 'gray')\n",
    "\n",
    "# Add beam size indicator\n",
    "ax1.text(3.5, 4, 'Beam Size = 2', fontsize=11, \n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "ax1.text(3.5, 3.7, 'Keep top 2 paths', fontsize=9, style='italic')\n",
    "\n",
    "# Right: Score comparison\n",
    "paths = [\n",
    "    'Le chat noir',\n",
    "    'Un chat noir',\n",
    "    'Le chien noir',\n",
    "    'Le chat blanc',\n",
    "]\n",
    "scores = [0.612, 0.084, 0.038, 0.072]\n",
    "colors = ['#4ECDC4', '#FF6B6B', '#E0E0E0', '#E0E0E0']\n",
    "\n",
    "bars = ax2.barh(range(len(paths)), scores, color=colors)\n",
    "ax2.set_yticks(range(len(paths)))\n",
    "ax2.set_yticklabels(paths)\n",
    "ax2.set_xlabel('Cumulative Score')\n",
    "ax2.set_title('Path Scores', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for bar, score in zip(bars, scores):\n",
    "    ax2.text(score + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "            f'{score:.3f}', va='center')\n",
    "\n",
    "# Mark selected paths\n",
    "ax2.text(0.7, 3.5, 'Selected', fontsize=10, \n",
    "        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "ax2.text(0.7, 1.5, 'Pruned', fontsize=10,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Beam Search Strategy:\")\n",
    "print(\"1. At each step, expand all possible next words\")\n",
    "print(\"2. Score each path by cumulative probability\")\n",
    "print(\"3. Keep only top-k paths (beam size)\")\n",
    "print(\"4. Continue until reaching end token or max length\")\n",
    "print(\"\\nThis avoids getting stuck with early bad choices!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "Let's summarize what we've learned about sequence-to-sequence models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary visualization\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Timeline of improvements\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "years = [2014, 2015, 2016, 2017]\n",
    "models = ['Basic\\nSeq2Seq', 'Attention\\nMechanism', 'Google\\nNMT', 'Transformer']\n",
    "improvements = [1, 3.5, 7, 10]\n",
    "\n",
    "ax1.plot(years, improvements, 'o-', linewidth=2, markersize=10, color='#4ECDC4')\n",
    "for year, model, imp in zip(years, models, improvements):\n",
    "    ax1.annotate(model, (year, imp), \n",
    "                textcoords=\"offset points\", xytext=(0,10), ha='center',\n",
    "                fontsize=9, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Performance (relative)')\n",
    "ax1.set_title('Evolution of Seq2Seq Models')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Key components\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "components = ['Encoder', 'Decoder', 'Attention', 'Beam\\nSearch']\n",
    "importance = [8, 8, 10, 6]\n",
    "colors_comp = ['#4ECDC4', '#FF6B6B', '#95E77E', '#FAB563']\n",
    "\n",
    "bars = ax2.bar(components, importance, color=colors_comp)\n",
    "ax2.set_ylabel('Importance Score')\n",
    "ax2.set_title('Key Components')\n",
    "ax2.set_ylim([0, 12])\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Problem solved\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "problems = ['Variable\\nLength', 'Information\\nBottleneck', 'Long\\nDependencies', 'Search\\nStrategy']\n",
    "solutions = ['Encoder-\\nDecoder', 'Attention', 'Attention', 'Beam\\nSearch']\n",
    "y_pos = np.arange(len(problems))\n",
    "\n",
    "ax3.barh(y_pos, [1, 1, 1, 1], color='#E0E0E0', alpha=0.3)\n",
    "ax3.set_yticks(y_pos)\n",
    "ax3.set_yticklabels(problems)\n",
    "ax3.set_xlabel('Solution')\n",
    "ax3.set_title('Problems Solved')\n",
    "ax3.set_xlim([0, 1.2])\n",
    "\n",
    "for i, sol in enumerate(solutions):\n",
    "    ax3.text(0.5, i, sol, ha='center', va='center',\n",
    "            fontsize=10, fontweight='bold', color='#2C3E50')\n",
    "\n",
    "# Applications\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "applications = ['Translation', 'Summarization', 'Q&A', 'Code\\nGeneration']\n",
    "adoption = [95, 70, 80, 60]\n",
    "\n",
    "ax4.pie(adoption, labels=applications, autopct='%1.0f%%',\n",
    "       colors=['#4ECDC4', '#FF6B6B', '#95E77E', '#FAB563'],\n",
    "       startangle=90)\n",
    "ax4.set_title('Industry Adoption (%)')\n",
    "\n",
    "plt.suptitle('Sequence-to-Sequence Models: Complete Picture', \n",
    "            fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"KEY TAKEAWAYS FROM WEEK 4\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"1. PROBLEM: Variable-length sequences don't map 1-to-1\")\n",
    "print(\"   SOLUTION: Encoder-Decoder architecture\")\n",
    "print()\n",
    "print(\"2. PROBLEM: Fixed-size context vectors lose information\")\n",
    "print(\"   SOLUTION: Attention mechanism\")\n",
    "print()\n",
    "print(\"3. KEY INSIGHT: Let the model learn what to focus on\")\n",
    "print(\"   - Don't compress everything\")\n",
    "print(\"   - Keep all encoder states\")\n",
    "print(\"   - Use attention to select relevant information\")\n",
    "print()\n",
    "print(\"4. MODERN IMPACT:\")\n",
    "print(\"   - Google Translate\")\n",
    "print(\"   - GitHub Copilot\")\n",
    "print(\"   - ChatGPT (uses attention at its core)\")\n",
    "print()\n",
    "print(\"Next Week: We'll see how Transformers take attention\")\n",
    "print(\"           to the extreme - 'Attention is All You Need'!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises for Practice\n",
    "\n",
    "Try these exercises to deepen your understanding:\n",
    "\n",
    "1. **Modify the SimpleEncoder** to use different aggregation methods (max pooling, mean pooling)\n",
    "2. **Implement multiplicative attention** and compare with dot-product attention\n",
    "3. **Visualize attention** for a longer sentence and observe the patterns\n",
    "4. **Experiment with beam size** - how does it affect translation quality vs speed?\n",
    "5. **Build a toy translator** using the concepts learned\n",
    "\n",
    "Remember: The key insight of seq2seq models is that we don't need to map inputs to outputs directly - we can use an intermediate representation and attention to handle variable-length sequences!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}