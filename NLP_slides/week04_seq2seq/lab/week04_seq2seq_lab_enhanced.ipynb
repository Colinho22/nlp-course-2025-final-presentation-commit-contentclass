{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Sequence-to-Sequence Models - Enhanced Interactive Lab\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Build encoder-decoder models from scratch with modern understanding\n",
    "- Visualize the information bottleneck problem and its solutions\n",
    "- Implement attention mechanism step-by-step\n",
    "- Connect seq2seq principles to 2024 AI systems (ChatGPT, GitHub Copilot)\n",
    "- Experience the evolution from 2014 research to production systems\n",
    "\n",
    "## üìö Prerequisites Check\n",
    "Before starting, make sure you understand:\n",
    "- RNNs and LSTMs (Week 3)\n",
    "- Backpropagation basics\n",
    "- Basic probability and softmax\n",
    "- Why fixed-length limitations matter\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced setup with modern libraries and consistent styling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set consistent style for all visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Educational color scheme (consistent with course materials)\n",
    "COLOR_CURRENT = '#FF6B6B'   # Red - current position/focus\n",
    "COLOR_CONTEXT = '#4ECDC4'   # Teal - context/surrounding\n",
    "COLOR_PREDICT = '#95E77E'   # Green - predictions/output\n",
    "COLOR_NEUTRAL = '#E0E0E0'   # Gray - neutral elements\n",
    "COLOR_ATTENTION = '#FAB563' # Orange - attention mechanism\n",
    "COLOR_ENCODER = '#74B3F7'   # Blue - encoder components\n",
    "COLOR_DECODER = '#F06292'   # Pink - decoder components\n",
    "COLOR_BOTTLENECK = '#FF5722' # Red-orange - bottleneck problem\n",
    "\n",
    "# Helper functions for consistent visualizations\n",
    "def setup_plot(figsize=(10, 6), title='', xlabel='', ylabel=''):\n",
    "    \"\"\"Setup plot with consistent styling.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    return fig, ax\n",
    "\n",
    "def plot_attention_heatmap(attention_matrix, source_words, target_words, title='Attention Weights'):\n",
    "    \"\"\"Create consistent attention heatmap visualizations.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    im = sns.heatmap(attention_matrix, \n",
    "                    xticklabels=source_words,\n",
    "                    yticklabels=target_words,\n",
    "                    cmap='Blues',\n",
    "                    cbar_kws={'label': 'Attention Weight'},\n",
    "                    linewidths=0.5,\n",
    "                    linecolor='gray',\n",
    "                    square=True,\n",
    "                    ax=ax)\n",
    "    \n",
    "    ax.set_xlabel('Source Words', fontsize=12)\n",
    "    ax.set_ylabel('Target Words', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add value annotations for high attention\n",
    "    for i in range(len(target_words)):\n",
    "        for j in range(len(source_words)):\n",
    "            if attention_matrix[i, j] > 0.3:\n",
    "                ax.text(j + 0.5, i + 0.5, f'{attention_matrix[i, j]:.2f}',\n",
    "                       ha='center', va='center', color='white', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_modern_context_box(text, color=COLOR_CONTEXT):\n",
    "    \"\"\"Create modern-looking info boxes.\"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    style = f\"\"\"\n",
    "    <div style=\"\n",
    "        background-color: {color}20;\n",
    "        border-left: 4px solid {color};\n",
    "        padding: 15px;\n",
    "        margin: 10px 0;\n",
    "        border-radius: 5px;\n",
    "        font-family: Arial, sans-serif;\n",
    "    \">\n",
    "        <strong>{text}</strong>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(style))\n",
    "\n",
    "print(\"üöÄ Enhanced Week 4 Lab Setup Complete!\")\n",
    "print(\"üìä Educational color scheme loaded\")\n",
    "print(\"üîß Helper functions ready\")\n",
    "print(\"üéØ Ready to explore seq2seq models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The 2024 Perspective - Why This Still Matters\n",
    "\n",
    "Before diving into the technical details, let's understand why seq2seq models remain relevant in the age of ChatGPT and modern AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modern applications that still use seq2seq principles\n",
    "modern_applications = {\n",
    "    'Google Translate (2024)': {\n",
    "        'daily_usage': '1+ billion translations',\n",
    "        'languages': '100+ language pairs',\n",
    "        'architecture': 'Transformer encoder-decoder',\n",
    "        'improvement_since_2014': '300% BLEU score increase'\n",
    "    },\n",
    "    'GitHub Copilot': {\n",
    "        'daily_usage': '1+ million developers',\n",
    "        'task': 'Comment ‚Üí Code generation',\n",
    "        'architecture': 'Modified transformer decoder',\n",
    "        'productivity_gain': '40% faster development'\n",
    "    },\n",
    "    'Email Summarization': {\n",
    "        'daily_usage': 'Billions of emails (Outlook, Gmail)',\n",
    "        'task': 'Long email ‚Üí Key points',\n",
    "        'architecture': 'Encoder-decoder with attention',\n",
    "        'time_saved': '20 minutes per worker per day'\n",
    "    },\n",
    "    'Customer Service AI': {\n",
    "        'daily_usage': '80% of first-line support',\n",
    "        'task': 'Query ‚Üí Context-aware response',\n",
    "        'architecture': 'Seq2seq + retrieval',\n",
    "        'cost_reduction': '60% support cost decrease'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create modern impact visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Evolution timeline\n",
    "years = [2014, 2015, 2016, 2017, 2018, 2020, 2022, 2024]\n",
    "capabilities = ['Research demo', 'Basic attention', 'Production ready', \n",
    "                'Transformer breakthrough', 'BERT era', 'GPT-3 scale', \n",
    "                'ChatGPT launch', 'Multi-modal AI']\n",
    "impact_scores = [1, 2, 4, 7, 8, 9, 10, 11]\n",
    "\n",
    "ax1.plot(years, impact_scores, 'o-', linewidth=3, markersize=8, color=COLOR_PREDICT)\n",
    "for year, cap, score in zip(years, capabilities, impact_scores):\n",
    "    ax1.annotate(cap, (year, score), \n",
    "                textcoords=\"offset points\", xytext=(0,10), ha='center',\n",
    "                fontsize=9, rotation=45,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='wheat', alpha=0.7))\n",
    "\n",
    "ax1.set_xlabel('Year', fontsize=12)\n",
    "ax1.set_ylabel('Industry Impact', fontsize=12)\n",
    "ax1.set_title('Seq2Seq Evolution: From Research to Production', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Market impact\n",
    "markets = ['Translation\\nServices', 'Code\\nAssistance', 'Content\\nSummarization', 'Customer\\nSupport']\n",
    "market_size = [15.7, 8.5, 12.3, 45.2]  # Billions USD\n",
    "\n",
    "bars = ax2.bar(markets, market_size, color=[COLOR_CONTEXT, COLOR_PREDICT, COLOR_ATTENTION, COLOR_DECODER])\n",
    "ax2.set_ylabel('Market Size (Billion USD)', fontsize=12)\n",
    "ax2.set_title('2024 Market Impact of Seq2Seq Technologies', fontsize=14, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, market_size):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "            f'${value}B', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Performance evolution\n",
    "model_names = ['Vanilla\\nSeq2Seq\\n(2014)', 'With\\nAttention\\n(2015)', \n",
    "               'Google NMT\\n(2016)', 'Transformer\\n(2017)', 'GPT-3\\n(2020)', 'ChatGPT\\n(2022)']\n",
    "parameters = [10, 20, 80, 65, 175000, 1700000]  # Millions\n",
    "quality_scores = [25, 35, 45, 52, 65, 70]  # BLEU scores\n",
    "\n",
    "# Use log scale for parameters\n",
    "ax3_twin = ax3.twinx()\n",
    "bars = ax3.bar(range(len(model_names)), np.log10(parameters), \n",
    "              color=COLOR_ENCODER, alpha=0.7, label='Parameters (log scale)')\n",
    "line = ax3_twin.plot(range(len(model_names)), quality_scores, 'o-', \n",
    "                    linewidth=3, markersize=8, color=COLOR_CURRENT, label='BLEU Score')\n",
    "\n",
    "ax3.set_xlabel('Model Evolution', fontsize=12)\n",
    "ax3.set_ylabel('Parameters (log‚ÇÅ‚ÇÄ millions)', fontsize=12)\n",
    "ax3_twin.set_ylabel('Translation Quality (BLEU)', fontsize=12)\n",
    "ax3.set_title('Scale and Performance Evolution', fontsize=14, fontweight='bold')\n",
    "ax3.set_xticks(range(len(model_names)))\n",
    "ax3.set_xticklabels(model_names, fontsize=9)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add actual parameter counts\n",
    "for i, (bar, param) in enumerate(zip(bars, parameters)):\n",
    "    if param < 1000:\n",
    "        label = f'{param}M'\n",
    "    else:\n",
    "        label = f'{param/1000:.1f}B'\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "            label, ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 4. Your daily interactions\n",
    "interactions = ['Google\\nTranslate', 'Copilot\\nCode Help', 'Email\\nSummary', \n",
    "                'Chat\\nResponses', 'Voice\\nAssistants']\n",
    "daily_usage_hours = [0.1, 2.0, 0.5, 1.5, 0.3]  # Average hours per day\n",
    "\n",
    "wedges, texts, autotexts = ax4.pie(daily_usage_hours, labels=interactions, autopct='%1.1f hrs',\n",
    "                                  colors=[COLOR_CONTEXT, COLOR_PREDICT, COLOR_ATTENTION, \n",
    "                                         COLOR_DECODER, COLOR_ENCODER],\n",
    "                                  startangle=90)\n",
    "ax4.set_title('Your Daily Seq2Seq Interactions (Avg Hours)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "create_modern_context_box(\n",
    "    \"üí° Modern Insight: Every time you use Google Translate, GitHub Copilot, or \"\n",
    "    \"get email summaries, you're using principles you'll learn in this lab!\",\n",
    "    COLOR_ATTENTION\n",
    ")\n",
    "\n",
    "print(\"üåü Ready to understand the technology behind your daily AI tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Variable-Length Challenge (The Core Problem)\n",
    "\n",
    "Let's start by understanding why translation was so difficult for early neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced translation examples with 2024 context\n",
    "translation_examples = [\n",
    "    (\"I love you\", \"Je t'aime\", \"French\", 2),\n",
    "    (\"I love you\", \"Ich liebe dich\", \"German\", 3),\n",
    "    (\"I love you\", \"Ti amo\", \"Italian\", 2),\n",
    "    (\"I love you\", \"Te amo\", \"Spanish\", 2),\n",
    "    (\"I love you\", \"Aishiteru\", \"Japanese\", 1),\n",
    "    (\"Good morning everyone\", \"Guten Morgen allerseits\", \"German\", 3),\n",
    "    (\"How are you doing today?\", \"Comment allez-vous aujourd'hui?\", \"French\", 3),\n",
    "    (\"Thank you very much\", \"Muchas gracias\", \"Spanish\", 2),\n",
    "]\n",
    "\n",
    "# Create comprehensive length analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Word count comparison\n",
    "languages = [ex[2] for ex in translation_examples[:5]]\n",
    "english_lengths = [len(ex[0].split()) for ex in translation_examples[:5]]\n",
    "target_lengths = [ex[3] for ex in translation_examples[:5]]\n",
    "\n",
    "x = np.arange(len(languages))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, english_lengths, width, label='English', color=COLOR_ENCODER, alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, target_lengths, width, label='Target Language', color=COLOR_DECODER, alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Language Pair', fontsize=12)\n",
    "ax1.set_ylabel('Number of Words', fontsize=12)\n",
    "ax1.set_title('\"I Love You\" - Word Count Variations', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(languages)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar1, bar2, eng_len, tgt_len in zip(bars1, bars2, english_lengths, target_lengths):\n",
    "    ax1.text(bar1.get_x() + bar1.get_width()/2, bar1.get_height() + 0.05,\n",
    "            str(eng_len), ha='center', va='bottom', fontweight='bold')\n",
    "    ax1.text(bar2.get_x() + bar2.get_width()/2, bar2.get_height() + 0.05,\n",
    "            str(tgt_len), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Real translation length scatter (no correlation)\n",
    "np.random.seed(42)\n",
    "# Simulate realistic translation data\n",
    "english_sentence_lengths = np.random.randint(1, 50, 100)\n",
    "# Add realistic variance - some correlation but lots of noise\n",
    "french_sentence_lengths = english_sentence_lengths + np.random.randint(-5, 8, 100)\n",
    "french_sentence_lengths = np.maximum(1, french_sentence_lengths)  # No negative lengths\n",
    "\n",
    "ax2.scatter(english_sentence_lengths, french_sentence_lengths, \n",
    "           s=60, alpha=0.6, color=COLOR_CURRENT, edgecolors='white', linewidth=0.5)\n",
    "ax2.plot([0, 50], [0, 50], 'k--', alpha=0.3, linewidth=2, label='Perfect 1:1 mapping')\n",
    "ax2.set_xlabel('English Sentence Length (words)', fontsize=12)\n",
    "ax2.set_ylabel('French Sentence Length (words)', fontsize=12)\n",
    "ax2.set_title('Real Translation Data: No Fixed Relationship', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add correlation coefficient\n",
    "correlation = np.corrcoef(english_sentence_lengths, french_sentence_lengths)[0, 1]\n",
    "ax2.text(0.05, 0.95, f'Correlation: {correlation:.2f}\\n(Weak!)', \n",
    "        transform=ax2.transAxes, fontsize=11, \n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# 3. Failed RNN approaches\n",
    "approaches = ['Pad to Max\\nLength', 'Truncate\\nLong Text', 'Force 1:1\\nMapping', 'Multiple\\nModels']\n",
    "problems = ['Wasteful\\nComputation', 'Information\\nLoss', 'Architectural\\nLimitation', 'Complexity\\nExplosion']\n",
    "severity = [60, 85, 95, 70]  # Problem severity percentage\n",
    "\n",
    "bars = ax3.barh(range(len(approaches)), severity, \n",
    "               color=[COLOR_BOTTLENECK if s > 80 else COLOR_ATTENTION for s in severity])\n",
    "ax3.set_yticks(range(len(approaches)))\n",
    "ax3.set_yticklabels(approaches)\n",
    "ax3.set_xlabel('Problem Severity (%)', fontsize=12)\n",
    "ax3.set_title('Why Traditional Approaches Failed', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add problem descriptions\n",
    "for i, (bar, problem) in enumerate(zip(bars, problems)):\n",
    "    ax3.text(bar.get_width() + 2, bar.get_y() + bar.get_height()/2,\n",
    "            problem, va='center', fontsize=10, style='italic')\n",
    "\n",
    "# 4. The breakthrough insight\n",
    "ax4.axis('off')\n",
    "ax4.text(0.5, 0.8, 'üéØ The Breakthrough Insight', ha='center', va='center',\n",
    "        transform=ax4.transAxes, fontsize=18, fontweight='bold', color=COLOR_CURRENT)\n",
    "\n",
    "insight_text = \"\"\"\n",
    "SEPARATE encoding from decoding!\n",
    "\n",
    "1. ENCODER: Compress input to understanding\n",
    "2. DECODER: Expand understanding to output\n",
    "3. VARIABLE LENGTHS: Input ‚â† Output length\n",
    "\n",
    "Just like human translation:\n",
    "‚Ä¢ Read entire source sentence\n",
    "‚Ä¢ Understand the meaning\n",
    "‚Ä¢ Generate target sentence\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.5, 0.4, insight_text, ha='center', va='center',\n",
    "        transform=ax4.transAxes, fontsize=12, \n",
    "        bbox=dict(boxstyle='round,pad=1', facecolor=COLOR_PREDICT, alpha=0.2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "create_modern_context_box(\n",
    "    \"üîë Key Insight: The encoder-decoder architecture mimics human translation - \"\n",
    "    \"understand first, then generate. This simple idea revolutionized AI!\",\n",
    "    COLOR_PREDICT\n",
    ")\n",
    "\n",
    "print(\"‚ú® Now you understand why this breakthrough was so important!\")\n",
    "print(\"üöÄ Let's build our own encoder-decoder model...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building Your Own Encoder-Decoder\n",
    "\n",
    "Let's implement a simple but complete encoder-decoder model to understand the core concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedEncoder:\n",
    "    \"\"\"Enhanced encoder with better visualization and modern understanding.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size=6):\n",
    "        self.hidden_size = hidden_size\n",
    "        # More realistic word embeddings (based on semantic similarity)\n",
    "        self.embeddings = {\n",
    "            # Animals cluster\n",
    "            'cat': np.array([0.8, 0.1, 0.05, 0.02, 0.02, 0.01]),\n",
    "            'dog': np.array([0.75, 0.15, 0.05, 0.02, 0.02, 0.01]),\n",
    "            # Actions cluster\n",
    "            'sat': np.array([0.1, 0.8, 0.05, 0.02, 0.02, 0.01]),\n",
    "            'sleeps': np.array([0.15, 0.75, 0.05, 0.02, 0.02, 0.01]),\n",
    "            # Objects cluster\n",
    "            'mat': np.array([0.05, 0.1, 0.8, 0.02, 0.02, 0.01]),\n",
    "            'chair': np.array([0.05, 0.1, 0.75, 0.05, 0.02, 0.03]),\n",
    "            # Function words\n",
    "            'the': np.array([0.02, 0.02, 0.02, 0.9, 0.02, 0.02]),\n",
    "            'on': np.array([0.02, 0.02, 0.02, 0.02, 0.9, 0.02]),\n",
    "        }\n",
    "        \n",
    "        # Initialize RNN weights\n",
    "        self.W_h = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.W_x = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.b = np.zeros(hidden_size)\n",
    "    \n",
    "    def encode(self, sentence: List[str]) -> Tuple[np.ndarray, List[np.ndarray]]:\n",
    "        \"\"\"Encode sentence with proper RNN dynamics.\"\"\"\n",
    "        hidden = np.zeros(self.hidden_size)\n",
    "        all_states = []\n",
    "        \n",
    "        print(f\"üîç Encoding: {' '.join(sentence)}\")\n",
    "        \n",
    "        for i, word in enumerate(sentence):\n",
    "            if word in self.embeddings:\n",
    "                # More realistic RNN update\n",
    "                x_t = self.embeddings[word]\n",
    "                hidden = np.tanh(self.W_h @ hidden + self.W_x @ x_t + self.b)\n",
    "                all_states.append(hidden.copy())\n",
    "                \n",
    "                print(f\"  Step {i+1}: '{word}' ‚Üí hidden state updated\")\n",
    "            else:\n",
    "                print(f\"  Step {i+1}: '{word}' ‚Üí unknown word (using zero vector)\")\n",
    "                all_states.append(hidden.copy())\n",
    "        \n",
    "        print(f\"‚úÖ Encoding complete. Context vector: {hidden[:3]:.2f}...\")\n",
    "        return hidden, all_states\n",
    "\n",
    "class EnhancedDecoder:\n",
    "    \"\"\"Enhanced decoder with more realistic generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size=6):\n",
    "        self.hidden_size = hidden_size\n",
    "        # French vocabulary with semantic structure\n",
    "        self.vocab = {\n",
    "            0: 'le',      # articles\n",
    "            1: 'la',\n",
    "            2: 'chat',    # animals\n",
    "            3: 'chien',\n",
    "            4: 'dort',    # actions\n",
    "            5: 'mange',\n",
    "            6: 'sur',     # prepositions\n",
    "            7: 'dans',\n",
    "            8: 'tapis',   # objects\n",
    "            9: '<EOS>',   # end token\n",
    "        }\n",
    "        \n",
    "        # Output projection weights\n",
    "        self.W_out = np.random.randn(len(self.vocab), hidden_size) * 0.1\n",
    "        self.b_out = np.zeros(len(self.vocab))\n",
    "        \n",
    "        # Decoder RNN weights\n",
    "        self.W_h = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.b_h = np.zeros(hidden_size)\n",
    "    \n",
    "    def decode_step(self, hidden: np.ndarray, context: np.ndarray) -> Tuple[int, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Single decoding step.\"\"\"\n",
    "        # Update hidden state with context\n",
    "        hidden = np.tanh(self.W_h @ hidden + context + self.b_h)\n",
    "        \n",
    "        # Compute output probabilities\n",
    "        logits = self.W_out @ hidden + self.b_out\n",
    "        probs = np.exp(logits) / np.sum(np.exp(logits))  # Softmax\n",
    "        \n",
    "        # Sample word (you could also use argmax for deterministic)\n",
    "        word_idx = np.random.choice(len(self.vocab), p=probs)\n",
    "        \n",
    "        return word_idx, hidden, probs\n",
    "    \n",
    "    def decode(self, context: np.ndarray, max_length: int = 8) -> Tuple[List[str], List[np.ndarray]]:\n",
    "        \"\"\"Generate complete sequence.\"\"\"\n",
    "        output_words = []\n",
    "        hidden = context.copy()\n",
    "        all_probs = []\n",
    "        \n",
    "        print(f\"üéØ Decoding from context vector...\")\n",
    "        \n",
    "        for step in range(max_length):\n",
    "            word_idx, hidden, probs = self.decode_step(hidden, context)\n",
    "            word = self.vocab[word_idx]\n",
    "            \n",
    "            print(f\"  Step {step+1}: Generated '{word}' (prob: {probs[word_idx]:.3f})\")\n",
    "            \n",
    "            output_words.append(word)\n",
    "            all_probs.append(probs)\n",
    "            \n",
    "            # Stop if we generate end token\n",
    "            if word == '<EOS>':\n",
    "                break\n",
    "        \n",
    "        print(f\"‚úÖ Generation complete: {' '.join(output_words)}\")\n",
    "        return output_words, all_probs\n",
    "\n",
    "# Test the enhanced encoder-decoder\n",
    "print(\"üî® Building Enhanced Encoder-Decoder Model...\")\n",
    "encoder = EnhancedEncoder()\n",
    "decoder = EnhancedDecoder()\n",
    "\n",
    "# Test with multiple examples\n",
    "test_sentences = [\n",
    "    ['the', 'cat', 'sat'],\n",
    "    ['the', 'dog', 'sleeps'],\n",
    "    ['cat', 'on', 'mat']\n",
    "]\n",
    "\n",
    "results = []\n",
    "for sentence in test_sentences:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    context_vector, encoder_states = encoder.encode(sentence)\n",
    "    output_sequence, decoder_probs = decoder.decode(context_vector)\n",
    "    results.append((sentence, output_sequence, encoder_states, decoder_probs))\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"üìä Results Summary:\")\n",
    "for i, (inp, out, _, _) in enumerate(results):\n",
    "    print(f\"  {i+1}. '{' '.join(inp)}' ‚Üí '{' '.join(out)}'\")\n",
    "\n",
    "create_modern_context_box(\n",
    "    \"ü§î Notice: The translations aren't perfect! This is because our model is \"\n",
    "    \"tiny and untrained. Real seq2seq models need millions of parameters and \"\n",
    "    \"large datasets. But the core principle is the same!\",\n",
    "    COLOR_ATTENTION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Information Bottleneck Problem\n",
    "\n",
    "This is the crucial insight that led to the attention mechanism. Let's see why compressing everything into one vector is problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced bottleneck analysis with modern understanding\n",
    "def analyze_information_bottleneck():\n",
    "    \"\"\"Comprehensive analysis of the bottleneck problem.\"\"\"\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Information theory perspective\n",
    "    sentence_lengths = np.arange(1, 101)\n",
    "    bits_per_word = 10  # Rough estimate\n",
    "    total_information = sentence_lengths * bits_per_word\n",
    "    \n",
    "    context_sizes = [128, 256, 512, 1024]\n",
    "    colors = [COLOR_BOTTLENECK, COLOR_ATTENTION, COLOR_CONTEXT, COLOR_PREDICT]\n",
    "    \n",
    "    for context_size, color in zip(context_sizes, colors):\n",
    "        information_loss = np.maximum(0, (total_information - context_size) / total_information * 100)\n",
    "        ax1.plot(sentence_lengths, information_loss, linewidth=2, \n",
    "                color=color, label=f'{context_size}-dim context')\n",
    "    \n",
    "    ax1.axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Critical 50% loss')\n",
    "    ax1.set_xlabel('Sentence Length (words)', fontsize=12)\n",
    "    ax1.set_ylabel('Information Loss (%)', fontsize=12)\n",
    "    ax1.set_title('Information Bottleneck Analysis', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(0, 100)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # 2. Real performance data (simulated based on research)\n",
    "    # Data inspired by early seq2seq papers\n",
    "    sentence_lengths_real = [5, 10, 15, 20, 25, 30, 40, 50]\n",
    "    bleu_vanilla = [45, 42, 38, 32, 25, 18, 12, 8]  # Rapid degradation\n",
    "    bleu_attention = [46, 44, 42, 40, 38, 35, 30, 25]  # Much more stable\n",
    "    \n",
    "    ax2.plot(sentence_lengths_real, bleu_vanilla, 'o-', linewidth=3, markersize=8,\n",
    "            color=COLOR_BOTTLENECK, label='Vanilla Seq2Seq (2014)', markeredgecolor='white')\n",
    "    ax2.plot(sentence_lengths_real, bleu_attention, 'o-', linewidth=3, markersize=8,\n",
    "            color=COLOR_ATTENTION, label='With Attention (2015)', markeredgecolor='white')\n",
    "    \n",
    "    ax2.axhline(y=30, color='gray', linestyle=':', alpha=0.5, label='Acceptable Quality')\n",
    "    ax2.fill_between(sentence_lengths_real, 0, 30, alpha=0.1, color='red', label='Poor Quality')\n",
    "    ax2.fill_between(sentence_lengths_real, 30, 50, alpha=0.1, color='green', label='Good Quality')\n",
    "    \n",
    "    ax2.set_xlabel('Sentence Length (words)', fontsize=12)\n",
    "    ax2.set_ylabel('Translation Quality (BLEU)', fontsize=12)\n",
    "    ax2.set_title('Real Performance Impact of Bottleneck', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Context vector \"averaging\" effect\n",
    "    np.random.seed(42)\n",
    "    sentences = [\n",
    "        \"Hi\",\n",
    "        \"The cat sleeps\", \n",
    "        \"The quick brown fox jumps over\",\n",
    "        \"The International Conference on Machine Learning accepted our research paper\"\n",
    "    ]\n",
    "    \n",
    "    context_vectors = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        # Simulate how context vectors get \"averaged out\" with length\n",
    "        base_signal = np.random.randn(8) * 2  # Strong signal\n",
    "        noise = np.random.randn(8) * 0.5      # Noise from averaging\n",
    "        # Longer sentences = more averaged out = weaker signal\n",
    "        averaging_factor = 1.0 / np.sqrt(len(words))\n",
    "        context = (base_signal + noise) * averaging_factor\n",
    "        context_vectors.append(context)\n",
    "    \n",
    "    context_matrix = np.array(context_vectors)\n",
    "    im = ax3.imshow(context_matrix.T, aspect='auto', cmap='RdBu_r', \n",
    "                   vmin=-2, vmax=2)\n",
    "    \n",
    "    ax3.set_xlabel('Sentence Examples', fontsize=12)\n",
    "    ax3.set_ylabel('Context Vector Dimensions', fontsize=12)\n",
    "    ax3.set_title('Context Vector \"Washing Out\" Effect', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xticks(range(len(sentences)))\n",
    "    ax3.set_xticklabels([f'{len(s.split())} words' for s in sentences])\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax3, shrink=0.6)\n",
    "    cbar.set_label('Signal Strength', fontsize=10)\n",
    "    \n",
    "    # 4. Attention as solution preview\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Draw simple attention diagram\n",
    "    ax4.text(0.5, 0.9, 'üí° The Attention Solution', ha='center', va='center',\n",
    "            transform=ax4.transAxes, fontsize=16, fontweight='bold', color=COLOR_ATTENTION)\n",
    "    \n",
    "    # Before attention\n",
    "    ax4.text(0.2, 0.7, 'Before Attention:\\n(Bottleneck)', ha='center', va='center',\n",
    "            transform=ax4.transAxes, fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Draw compression arrow\n",
    "    ax4.arrow(0.05, 0.6, 0.3, 0, transform=ax4.transAxes, \n",
    "             head_width=0.02, head_length=0.03, fc=COLOR_BOTTLENECK, ec=COLOR_BOTTLENECK)\n",
    "    ax4.text(0.2, 0.55, 'All info ‚Üí 1 vector', ha='center', va='center',\n",
    "            transform=ax4.transAxes, fontsize=10, color=COLOR_BOTTLENECK)\n",
    "    \n",
    "    # After attention\n",
    "    ax4.text(0.8, 0.7, 'With Attention:\\n(No Bottleneck)', ha='center', va='center',\n",
    "            transform=ax4.transAxes, fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Draw attention arrows\n",
    "    for i, y_offset in enumerate([0.05, 0, -0.05]):\n",
    "        ax4.arrow(0.65, 0.6 + y_offset, 0.25, 0, transform=ax4.transAxes,\n",
    "                 head_width=0.015, head_length=0.02, \n",
    "                 fc=COLOR_ATTENTION, ec=COLOR_ATTENTION, alpha=0.7)\n",
    "    \n",
    "    ax4.text(0.8, 0.55, 'Access all states\\ndirectly', ha='center', va='center',\n",
    "            transform=ax4.transAxes, fontsize=10, color=COLOR_ATTENTION)\n",
    "    \n",
    "    # Key insight\n",
    "    insight_box = f\"\"\"\n",
    "üîë KEY INSIGHT:\n",
    "Don't compress everything!\n",
    "Keep all encoder states and let\n",
    "the decoder choose what to focus on.\n",
    "\n",
    "This is the foundation of modern AI!\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.5, 0.25, insight_box, ha='center', va='center',\n",
    "            transform=ax4.transAxes, fontsize=11,\n",
    "            bbox=dict(boxstyle='round,pad=0.8', facecolor=COLOR_PREDICT, alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the analysis\n",
    "analyze_information_bottleneck()\n",
    "\n",
    "create_modern_context_box(\n",
    "    \"üß† Think About It: This bottleneck problem is why early Google Translate \"\n",
    "    \"(pre-2016) struggled with long sentences. The attention mechanism \"\n",
    "    \"breakthrough solved this and enabled modern AI!\",\n",
    "    COLOR_CURRENT\n",
    ")\n",
    "\n",
    "print(\"\\nüéØ Next: Let's implement the attention mechanism that solved this problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implementing Attention - The Game Changer\n",
    "\n",
    "Now let's implement the attention mechanism that revolutionized seq2seq models and laid the foundation for transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModernAttentionModule:\n",
    "    \"\"\"Complete attention implementation with multiple variants.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size=6):\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Learnable parameters for additive attention (Bahdanau style)\n",
    "        self.W_a = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.U_a = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "        self.v_a = np.random.randn(hidden_size) * 0.1\n",
    "    \n",
    "    def dot_product_attention(self, query: np.ndarray, keys: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Simple dot product attention.\"\"\"\n",
    "        scores = [np.dot(query, key) for key in keys]\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        # Softmax with numerical stability\n",
    "        exp_scores = np.exp(scores - np.max(scores))\n",
    "        weights = exp_scores / np.sum(exp_scores)\n",
    "        \n",
    "        # Weighted sum\n",
    "        context = sum(w * k for w, k in zip(weights, keys))\n",
    "        \n",
    "        return weights, context\n",
    "    \n",
    "    def scaled_dot_product_attention(self, query: np.ndarray, keys: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Scaled dot product (used in Transformers).\"\"\"\n",
    "        d_k = len(keys[0])\n",
    "        scores = [np.dot(query, key) / np.sqrt(d_k) for key in keys]\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        exp_scores = np.exp(scores - np.max(scores))\n",
    "        weights = exp_scores / np.sum(exp_scores)\n",
    "        \n",
    "        context = sum(w * k for w, k in zip(weights, keys))\n",
    "        return weights, context\n",
    "    \n",
    "    def additive_attention(self, query: np.ndarray, keys: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Additive attention (Bahdanau et al. 2015).\"\"\"\n",
    "        scores = []\n",
    "        for key in keys:\n",
    "            # Compute attention energy\n",
    "            energy = np.tanh(self.W_a @ query + self.U_a @ key)\n",
    "            score = np.dot(self.v_a, energy)\n",
    "            scores.append(score)\n",
    "        \n",
    "        scores = np.array(scores)\n",
    "        exp_scores = np.exp(scores - np.max(scores))\n",
    "        weights = exp_scores / np.sum(exp_scores)\n",
    "        \n",
    "        context = sum(w * k for w, k in zip(weights, keys))\n",
    "        return weights, context\n",
    "\n",
    "# Test attention on realistic example\n",
    "attention_module = ModernAttentionModule()\n",
    "\n",
    "# Use encoder states from enhanced encoder\n",
    "encoder = EnhancedEncoder()\n",
    "test_sentence = ['the', 'cat', 'sat', 'on', 'the', 'mat']\n",
    "_, encoder_states = encoder.encode(test_sentence)\n",
    "\n",
    "# Simulate decoder states for generating different French words\n",
    "decoder_scenarios = [\n",
    "    (np.array([0.8, 0.1, 0.05, 0.02, 0.02, 0.01]), \"Generating 'chat' (cat)\"),\n",
    "    (np.array([0.1, 0.8, 0.05, 0.02, 0.02, 0.01]), \"Generating 'assis' (sat)\"),\n",
    "    (np.array([0.05, 0.1, 0.8, 0.02, 0.02, 0.01]), \"Generating 'tapis' (mat)\"),\n",
    "    (np.array([0.02, 0.02, 0.02, 0.9, 0.02, 0.02]), \"Generating 'le' (the)\"),\n",
    "]\n",
    "\n",
    "# Compare all attention types\n",
    "attention_types = [\n",
    "    ('Dot Product', attention_module.dot_product_attention),\n",
    "    ('Scaled Dot Product', attention_module.scaled_dot_product_attention),\n",
    "    ('Additive (Bahdanau)', attention_module.additive_attention)\n",
    "]\n",
    "\n",
    "# Create comprehensive attention visualization\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "scenario_colors = [COLOR_DECODER, COLOR_PREDICT, COLOR_CONTEXT, COLOR_ENCODER]\n",
    "\n",
    "for scenario_idx, (query, scenario_name) in enumerate(decoder_scenarios):\n",
    "    for type_idx, (type_name, attention_func) in enumerate(attention_types):\n",
    "        ax = plt.subplot(len(decoder_scenarios), len(attention_types), \n",
    "                        scenario_idx * len(attention_types) + type_idx + 1)\n",
    "        \n",
    "        weights, context = attention_func(query, encoder_states)\n",
    "        \n",
    "        # Create attention plot\n",
    "        bars = ax.bar(range(len(test_sentence)), weights, \n",
    "                     color=scenario_colors[scenario_idx], alpha=0.7)\n",
    "        \n",
    "        # Highlight maximum attention\n",
    "        max_idx = np.argmax(weights)\n",
    "        bars[max_idx].set_edgecolor('black')\n",
    "        bars[max_idx].set_linewidth(2)\n",
    "        bars[max_idx].set_alpha(1.0)\n",
    "        \n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.set_xticks(range(len(test_sentence)))\n",
    "        ax.set_xticklabels(test_sentence, rotation=45, fontsize=10)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, weight in zip(bars, weights):\n",
    "            if weight > 0.1:  # Only label significant weights\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                       f'{weight:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        # Titles and labels\n",
    "        if scenario_idx == 0:\n",
    "            ax.set_title(f'{type_name}', fontsize=12, fontweight='bold')\n",
    "        if type_idx == 0:\n",
    "            ax.set_ylabel(f'{scenario_name}\\nAttention Weight', fontsize=11)\n",
    "        if scenario_idx == len(decoder_scenarios) - 1:\n",
    "            ax.set_xlabel('Source Words', fontsize=11)\n",
    "        \n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Attention Mechanisms Comparison: How Different Types Focus', \n",
    "            fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary of attention benefits\n",
    "print(\"\\nüéâ Attention Mechanism Benefits:\")\n",
    "print(\"1. üîì Eliminates information bottleneck\")\n",
    "print(\"2. üéØ Allows selective focus on relevant inputs\")\n",
    "print(\"3. üìà Dramatically improves long sequence performance\")\n",
    "print(\"4. üî¨ Provides interpretability (we can see what the model focuses on)\")\n",
    "print(\"5. üåü Foundation for modern transformers (self-attention)\")\n",
    "\n",
    "create_modern_context_box(\n",
    "    \"üöÄ Historical Impact: When Google implemented attention in 2016, \"\n",
    "    \"their translation quality improved by 60% overnight. This single \"\n",
    "    \"innovation enabled the AI revolution we see today!\",\n",
    "    COLOR_ATTENTION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Modern Translation with Attention\n",
    "\n",
    "Let's create a realistic translation example that shows how attention works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic attention pattern for complex translation\n",
    "def create_realistic_translation_attention():\n",
    "    \"\"\"Generate realistic attention patterns based on linguistic alignment.\"\"\"\n",
    "    \n",
    "    # Modern translation example (more complex than simple phrases)\n",
    "    source_sentence = \"The artificial intelligence research conference was held in Paris\"\n",
    "    target_sentence = \"La conf√©rence de recherche en intelligence artificielle s'est tenue √† Paris\"\n",
    "    \n",
    "    source_words = source_sentence.split()\n",
    "    target_words = target_sentence.split()\n",
    "    \n",
    "    print(f\"üî§ Source ({len(source_words)} words): {source_sentence}\")\n",
    "    print(f\"üî§ Target ({len(target_words)} words): {target_sentence}\")\n",
    "    print(f\"üìä Length ratio: {len(target_words)/len(source_words):.2f}\")\n",
    "    \n",
    "    # Create attention matrix based on linguistic knowledge\n",
    "    attention_matrix = np.zeros((len(target_words), len(source_words)))\n",
    "    \n",
    "    # Define realistic word alignments\n",
    "    alignments = [\n",
    "        (0, 0),     # La -> The\n",
    "        (1, 5),     # conf√©rence -> conference\n",
    "        (2, 6),     # de -> (of)\n",
    "        (3, 3),     # recherche -> research\n",
    "        (4, 6),     # en -> (in)\n",
    "        (5, 1),     # intelligence -> artificial\n",
    "        (5, 2),     # intelligence -> intelligence \n",
    "        (6, 2),     # artificielle -> intelligence\n",
    "        (6, 1),     # artificielle -> artificial\n",
    "        (7, 4),     # s'est -> was\n",
    "        (8, 7),     # tenue -> held\n",
    "        (9, 8),     # √† -> in\n",
    "        (10, 9),    # Paris -> Paris\n",
    "    ]\n",
    "    \n",
    "    # Add noise and create realistic attention\n",
    "    np.random.seed(42)\n",
    "    for tgt_idx in range(len(target_words)):\n",
    "        # Small random attention everywhere\n",
    "        attention_matrix[tgt_idx, :] = np.random.random(len(source_words)) * 0.05\n",
    "        \n",
    "        # Strong attention for aligned words\n",
    "        for align_tgt, align_src in alignments:\n",
    "            if align_tgt == tgt_idx:\n",
    "                attention_matrix[tgt_idx, align_src] += 0.6\n",
    "        \n",
    "        # Normalize\n",
    "        attention_matrix[tgt_idx, :] /= attention_matrix[tgt_idx, :].sum()\n",
    "    \n",
    "    # Create enhanced heatmap\n",
    "    plot_attention_heatmap(attention_matrix, source_words, target_words,\n",
    "                          'Modern Translation: Attention Alignment Patterns')\n",
    "    \n",
    "    # Analysis insights\n",
    "    print(\"\\nüîç Attention Pattern Analysis:\")\n",
    "    \n",
    "    # Find strongest alignments\n",
    "    for i, target_word in enumerate(target_words):\n",
    "        max_attention_idx = np.argmax(attention_matrix[i, :])\n",
    "        max_attention_value = attention_matrix[i, max_attention_idx]\n",
    "        source_word = source_words[max_attention_idx]\n",
    "        \n",
    "        if max_attention_value > 0.3:\n",
    "            print(f\"  '{target_word}' ‚Üê '{source_word}' (weight: {max_attention_value:.3f})\")\n",
    "    \n",
    "    return attention_matrix, source_words, target_words\n",
    "\n",
    "# Demonstrate multiple attention scenarios\n",
    "attention_matrix, source_words, target_words = create_realistic_translation_attention()\n",
    "\n",
    "# Show what happens without attention (bottleneck scenario)\n",
    "print(\"\\n‚ö†Ô∏è  Without Attention (Bottleneck Scenario):\")\n",
    "print(\"   All 10 source words ‚Üí 1 context vector ‚Üí 11 target words\")\n",
    "print(\"   Result: Information from 'artificial intelligence research' gets mixed together\")\n",
    "print(\"   Problem: Can't distinguish when to use 'intelligence' vs 'artificielle'\")\n",
    "\n",
    "print(\"\\n‚úÖ With Attention (Modern Solution):\")\n",
    "print(\"   Each target word can look at all 10 source words independently\")\n",
    "print(\"   Result: 'intelligence' focuses on 'artificial' + 'intelligence'\")\n",
    "print(\"   Benefit: Perfect alignment even for complex phrases\")\n",
    "\n",
    "create_modern_context_box(\n",
    "    \"üèÜ Real Impact: This attention mechanism increased Google Translate \"\n",
    "    \"accuracy from ~23 BLEU to ~38 BLEU (60% improvement) in 2016. \"\n",
    "    \"It's the same principle that powers ChatGPT today!\",\n",
    "    COLOR_ATTENTION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Beam Search - Finding the Best Path\n",
    "\n",
    "Even with attention, we need smart search strategies to find good translations. Let's implement and visualize beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced beam search with modern understanding\n",
    "class BeamSearchVisualizer:\n",
    "    \"\"\"Visualize beam search algorithm step by step.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_probs):\n",
    "        \"\"\"Initialize with vocabulary transition probabilities.\"\"\"\n",
    "        self.vocab_probs = vocab_probs\n",
    "        self.vocab = list(vocab_probs.keys())\n",
    "    \n",
    "    def beam_search(self, beam_size=3, max_length=5):\n",
    "        \"\"\"Run beam search with visualization.\"\"\"\n",
    "        # Initialize with START token\n",
    "        beams = [{'sequence': ['<START>'], 'score': 0.0, 'log_prob': 0.0}]\n",
    "        \n",
    "        all_steps = []  # Store for visualization\n",
    "        \n",
    "        for step in range(max_length):\n",
    "            print(f\"\\nüìç Step {step + 1}:\")\n",
    "            candidates = []\n",
    "            \n",
    "            for beam_idx, beam in enumerate(beams):\n",
    "                current_seq = beam['sequence']\n",
    "                current_score = beam['log_prob']\n",
    "                \n",
    "                # Get last word for transition\n",
    "                last_word = current_seq[-1]\n",
    "                \n",
    "                if last_word == '<EOS>' or last_word not in self.vocab_probs:\n",
    "                    # Finished sequence, just carry forward\n",
    "                    candidates.append(beam)\n",
    "                    continue\n",
    "                \n",
    "                # Get possible next words\n",
    "                next_word_probs = self.vocab_probs[last_word]\n",
    "                \n",
    "                print(f\"  Beam {beam_idx+1}: {' '.join(current_seq[1:])} (score: {current_score:.3f})\")\n",
    "                \n",
    "                # Expand to all possible next words\n",
    "                for next_word, prob in next_word_probs.items():\n",
    "                    new_sequence = current_seq + [next_word]\n",
    "                    new_log_prob = current_score + np.log(prob)\n",
    "                    new_score = np.exp(new_log_prob / len(new_sequence))  # Length normalized\n",
    "                    \n",
    "                    candidates.append({\n",
    "                        'sequence': new_sequence,\n",
    "                        'score': new_score,\n",
    "                        'log_prob': new_log_prob,\n",
    "                        'last_word': next_word,\n",
    "                        'last_prob': prob\n",
    "                    })\n",
    "                    \n",
    "                    if len(next_word_probs) <= 3:  # Only show details for smaller expansions\n",
    "                        print(f\"    + '{next_word}' (p={prob:.3f}) ‚Üí total_score={new_score:.3f}\")\n",
    "            \n",
    "            # Keep top beam_size candidates\n",
    "            candidates.sort(key=lambda x: x['score'], reverse=True)\n",
    "            beams = candidates[:beam_size]\n",
    "            \n",
    "            all_steps.append(beams.copy())\n",
    "            \n",
    "            print(f\"  üèÜ Top {beam_size} kept:\")\n",
    "            for i, beam in enumerate(beams):\n",
    "                seq_display = ' '.join(beam['sequence'][1:])  # Skip <START>\n",
    "                print(f\"    {i+1}. '{seq_display}' (score: {beam['score']:.3f})\")\n",
    "        \n",
    "        return beams, all_steps\n",
    "\n",
    "# Define realistic French transition probabilities\n",
    "# Simplified but realistic French language model\n",
    "french_transitions = {\n",
    "    '<START>': {'Le': 0.4, 'La': 0.3, 'Un': 0.2, 'Une': 0.1},\n",
    "    'Le': {'chat': 0.3, 'chien': 0.2, 'livre': 0.15, 'gar√ßon': 0.15, 'homme': 0.1, 'soleil': 0.1},\n",
    "    'La': {'fille': 0.25, 'maison': 0.2, 'voiture': 0.2, 'femme': 0.15, 'lune': 0.1, 'table': 0.1},\n",
    "    'Un': {'chat': 0.25, 'chien': 0.2, 'livre': 0.2, 'gar√ßon': 0.15, 'homme': 0.1, 'jour': 0.1},\n",
    "    'chat': {'noir': 0.3, 'blanc': 0.2, 'dort': 0.2, 'mange': 0.15, 'court': 0.1, '<EOS>': 0.05},\n",
    "    'chien': {'aboie': 0.3, 'court': 0.25, 'mange': 0.2, 'dort': 0.15, '<EOS>': 0.1},\n",
    "    'noir': {'dort': 0.4, 'mange': 0.3, 'court': 0.2, '<EOS>': 0.1},\n",
    "    'blanc': {'dort': 0.4, 'mange': 0.3, 'joue': 0.2, '<EOS>': 0.1},\n",
    "    'dort': {'bien': 0.3, 'sur': 0.25, 'dans': 0.2, '<EOS>': 0.25},\n",
    "    'mange': {'de': 0.3, 'beaucoup': 0.25, 'peu': 0.2, '<EOS>': 0.25},\n",
    "    'court': {'vite': 0.4, 'lentement': 0.2, 'dans': 0.2, '<EOS>': 0.2},\n",
    "}\n",
    "\n",
    "# Run beam search demonstration\n",
    "print(\"üîç Beam Search Demonstration: Generating French Sentences\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "beam_searcher = BeamSearchVisualizer(french_transitions)\n",
    "final_beams, search_steps = beam_searcher.beam_search(beam_size=3, max_length=4)\n",
    "\n",
    "# Visualize the search tree\n",
    "def visualize_beam_search_tree(search_steps):\n",
    "    \"\"\"Create tree visualization of beam search.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Left: Tree structure\n",
    "    ax1.set_xlim(-0.5, len(search_steps) + 0.5)\n",
    "    ax1.set_ylim(-0.5, 5)\n",
    "    ax1.set_title('Beam Search Tree Exploration', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Generation Step', fontsize=12)\n",
    "    ax1.set_ylabel('Beam Rank', fontsize=12)\n",
    "    \n",
    "    # Plot beam paths\n",
    "    colors = [COLOR_PREDICT, COLOR_ATTENTION, COLOR_CONTEXT, COLOR_DECODER, COLOR_ENCODER]\n",
    "    \n",
    "    for step_idx, step_beams in enumerate(search_steps):\n",
    "        for beam_idx, beam in enumerate(step_beams):\n",
    "            if len(beam['sequence']) > 1:  # Skip empty\n",
    "                y_pos = beam_idx\n",
    "                color = colors[beam_idx % len(colors)]\n",
    "                \n",
    "                # Draw node\n",
    "                circle = plt.Circle((step_idx, y_pos), 0.15, \n",
    "                                  facecolor=color, alpha=0.8, edgecolor='black')\n",
    "                ax1.add_patch(circle)\n",
    "                \n",
    "                # Add word label\n",
    "                last_word = beam['sequence'][-1]\n",
    "                if last_word != '<START>':\n",
    "                    ax1.text(step_idx, y_pos, last_word[:4], ha='center', va='center',\n",
    "                           fontsize=9, fontweight='bold', color='white')\n",
    "                \n",
    "                # Add score\n",
    "                ax1.text(step_idx, y_pos - 0.3, f'{beam[\"score\"]:.3f}',\n",
    "                        ha='center', va='center', fontsize=8)\n",
    "                \n",
    "                # Draw connection to previous step\n",
    "                if step_idx > 0:\n",
    "                    ax1.arrow(step_idx - 0.8, y_pos, 0.6, 0,\n",
    "                             head_width=0.08, head_length=0.1,\n",
    "                             fc=color, ec=color, alpha=0.6)\n",
    "    \n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Right: Final results comparison\n",
    "    final_sequences = []\n",
    "    final_scores = []\n",
    "    \n",
    "    for beam in final_beams:\n",
    "        sequence = ' '.join(beam['sequence'][1:])  # Remove <START>\n",
    "        final_sequences.append(sequence)\n",
    "        final_scores.append(beam['score'])\n",
    "    \n",
    "    bars = ax2.barh(range(len(final_sequences)), final_scores,\n",
    "                   color=[colors[i] for i in range(len(final_sequences))])\n",
    "    \n",
    "    ax2.set_yticks(range(len(final_sequences)))\n",
    "    ax2.set_yticklabels(final_sequences)\n",
    "    ax2.set_xlabel('Final Score (length-normalized)', fontsize=12)\n",
    "    ax2.set_title('Beam Search Results Ranking', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add score labels and ranking\n",
    "    for i, (bar, score) in enumerate(zip(bars, final_scores)):\n",
    "        ax2.text(score + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "                f'{score:.3f}', va='center', fontweight='bold')\n",
    "        \n",
    "        # Add ranking\n",
    "        rank_color = COLOR_PREDICT if i == 0 else COLOR_NEUTRAL\n",
    "        ax2.text(-0.05, bar.get_y() + bar.get_height()/2, f'#{i+1}',\n",
    "                ha='right', va='center', fontweight='bold', color=rank_color)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_beam_search_tree(search_steps)\n",
    "\n",
    "# Compare with greedy search\n",
    "print(\"\\nüÜö Beam Search vs Greedy Search Comparison:\")\n",
    "print(\"\\nGreedy Search (beam_size=1):\")\n",
    "greedy_beams, _ = beam_searcher.beam_search(beam_size=1, max_length=4)\n",
    "greedy_result = ' '.join(greedy_beams[0]['sequence'][1:])\n",
    "print(f\"  Result: {greedy_result}\")\n",
    "print(f\"  Score: {greedy_beams[0]['score']:.3f}\")\n",
    "\n",
    "print(f\"\\nBeam Search (beam_size=3):\")\n",
    "beam_result = ' '.join(final_beams[0]['sequence'][1:])\n",
    "print(f\"  Result: {beam_result}\")\n",
    "print(f\"  Score: {final_beams[0]['score']:.3f}\")\n",
    "\n",
    "if final_beams[0]['score'] > greedy_beams[0]['score']:\n",
    "    improvement = (final_beams[0]['score'] / greedy_beams[0]['score'] - 1) * 100\n",
    "    print(f\"\\nüéØ Beam search achieved {improvement:.1f}% better score!\")\n",
    "\n",
    "create_modern_context_box(\n",
    "    \"‚ö° Production Insight: Google Translate uses beam size 4-8 for the \"\n",
    "    \"quality-speed trade-off. GitHub Copilot uses beam size 1-2 for \"\n",
    "    \"fast code completion. The choice depends on your application!\",\n",
    "    COLOR_DECODER\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Connecting to Modern AI (2024 Perspective)\n",
    "\n",
    "Let's connect everything we've learned to the AI systems you use today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modern AI connections and evolution\n",
    "def create_modern_ai_timeline():\n",
    "    \"\"\"Show how seq2seq evolved into modern AI systems.\"\"\"\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Architecture evolution\n",
    "    architectures = {\n",
    "        '2014\\nVanilla Seq2Seq': {'params': 10, 'attention_heads': 0, 'performance': 25},\n",
    "        '2015\\nWith Attention': {'params': 20, 'attention_heads': 1, 'performance': 35},\n",
    "        '2017\\nTransformer': {'params': 65, 'attention_heads': 8, 'performance': 52},\n",
    "        '2018\\nBERT': {'params': 340, 'attention_heads': 12, 'performance': 58},\n",
    "        '2020\\nGPT-3': {'params': 175000, 'attention_heads': 96, 'performance': 65},\n",
    "        '2022\\nChatGPT': {'params': 1700000, 'attention_heads': 128, 'performance': 70},\n",
    "    }\n",
    "    \n",
    "    arch_names = list(architectures.keys())\n",
    "    params = [architectures[name]['params'] for name in arch_names]\n",
    "    heads = [architectures[name]['attention_heads'] for name in arch_names]\n",
    "    performance = [architectures[name]['performance'] for name in arch_names]\n",
    "    \n",
    "    # Plot parameter evolution (log scale)\n",
    "    x = np.arange(len(arch_names))\n",
    "    \n",
    "    # Parameters and attention heads\n",
    "    ax1_twin = ax1.twinx()\n",
    "    bars1 = ax1.bar(x - 0.2, np.log10(params), 0.4, color=COLOR_ENCODER, alpha=0.8, label='Parameters (log‚ÇÅ‚ÇÄM)')\n",
    "    bars2 = ax1_twin.bar(x + 0.2, heads, 0.4, color=COLOR_ATTENTION, alpha=0.8, label='Attention Heads')\n",
    "    \n",
    "    ax1.set_xlabel('Architecture Evolution', fontsize=12)\n",
    "    ax1.set_ylabel('Parameters (log‚ÇÅ‚ÇÄ millions)', fontsize=12, color=COLOR_ENCODER)\n",
    "    ax1_twin.set_ylabel('Number of Attention Heads', fontsize=12, color=COLOR_ATTENTION)\n",
    "    ax1.set_title('Scale Evolution: From Seq2Seq to ChatGPT', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(arch_names, rotation=45, fontsize=10)\n",
    "    \n",
    "    # Add parameter labels\n",
    "    for i, (bar, param) in enumerate(zip(bars1, params)):\n",
    "        if param < 1000:\n",
    "            label = f'{param}M'\n",
    "        else:\n",
    "            label = f'{param/1000:.0f}B'\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                label, ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # 2. Modern applications ecosystem\n",
    "    modern_apps = {\n",
    "        'Translation\\n(Google, DeepL)': 95,\n",
    "        'Code Generation\\n(Copilot, CodeT5)': 85,\n",
    "        'Summarization\\n(News, Email)': 80,\n",
    "        'Chatbots\\n(ChatGPT, Claude)': 90,\n",
    "        'Q&A Systems\\n(Search, Support)': 75,\n",
    "        'Content Creation\\n(Writing, Marketing)': 70\n",
    "    }\n",
    "    \n",
    "    apps = list(modern_apps.keys())\n",
    "    adoption = list(modern_apps.values())\n",
    "    colors_apps = [COLOR_CONTEXT, COLOR_PREDICT, COLOR_ATTENTION, \n",
    "                   COLOR_DECODER, COLOR_ENCODER, COLOR_CURRENT]\n",
    "    \n",
    "    bars = ax2.bar(range(len(apps)), adoption, color=colors_apps, alpha=0.8)\n",
    "    ax2.set_xlabel('Application Domain', fontsize=12)\n",
    "    ax2.set_ylabel('Industry Adoption (%)', fontsize=12)\n",
    "    ax2.set_title('2024: Seq2Seq Principles Everywhere', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xticks(range(len(apps)))\n",
    "    ax2.set_xticklabels(apps, rotation=45, fontsize=10)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    # Add adoption percentages\n",
    "    for bar, adopt in zip(bars, adoption):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                f'{adopt}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. Core principles that remained\n",
    "    principles = ['Encoder-Decoder\\nSeparation', 'Attention\\nMechanism', \n",
    "                  'Variable Length\\nI/O', 'Sequence\\nModeling']\n",
    "    seq2seq_usage = [100, 95, 100, 90]  # How much modern systems use these\n",
    "    transformer_enhancement = [80, 100, 100, 95]  # How transformers enhanced them\n",
    "    \n",
    "    x_princ = np.arange(len(principles))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax3.bar(x_princ - width/2, seq2seq_usage, width, \n",
    "                   color=COLOR_CONTEXT, alpha=0.8, label='Original Seq2Seq')\n",
    "    bars2 = ax3.bar(x_princ + width/2, transformer_enhancement, width,\n",
    "                   color=COLOR_PREDICT, alpha=0.8, label='Modern Enhancement')\n",
    "    \n",
    "    ax3.set_xlabel('Core Principles', fontsize=12)\n",
    "    ax3.set_ylabel('Usage in Modern AI (%)', fontsize=12)\n",
    "    ax3.set_title('Seq2Seq Principles in Modern AI', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xticks(x_princ)\n",
    "    ax3.set_xticklabels(principles, fontsize=10)\n",
    "    ax3.legend()\n",
    "    ax3.set_ylim(0, 110)\n",
    "    \n",
    "    # 4. Your daily interactions timeline\n",
    "    daily_interactions = [\n",
    "        ('Morning: Email summaries', COLOR_ATTENTION),\n",
    "        ('Work: Code completion', COLOR_PREDICT),\n",
    "        ('Lunch: Translate menu', COLOR_CONTEXT),\n",
    "        ('Afternoon: Chat with AI', COLOR_DECODER),\n",
    "        ('Evening: Voice assistant', COLOR_ENCODER)\n",
    "    ]\n",
    "    \n",
    "    ax4.axis('off')\n",
    "    ax4.set_title('Your Daily Seq2Seq Interactions', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i, (interaction, color) in enumerate(daily_interactions):\n",
    "        y_pos = 0.8 - i * 0.15\n",
    "        \n",
    "        # Draw time indicator\n",
    "        circle = plt.Circle((0.1, y_pos), 0.03, facecolor=color, alpha=0.8)\n",
    "        ax4.add_patch(circle)\n",
    "        \n",
    "        # Add interaction text\n",
    "        ax4.text(0.2, y_pos, interaction, ha='left', va='center',\n",
    "                transform=ax4.transAxes, fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Add seq2seq principle\n",
    "        principles_daily = [\n",
    "            '(Long email ‚Üí Short summary)',\n",
    "            '(Comment ‚Üí Code function)', \n",
    "            '(English ‚Üí Other language)',\n",
    "            '(Question ‚Üí Contextual answer)',\n",
    "            '(Speech ‚Üí Text ‚Üí Response)'\n",
    "        ]\n",
    "        \n",
    "        ax4.text(0.95, y_pos, principles_daily[i], ha='right', va='center',\n",
    "                transform=ax4.transAxes, fontsize=10, style='italic', color='gray')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_modern_ai_timeline()\n",
    "\n",
    "create_modern_context_box(\n",
    "    \"üåç Global Impact: The seq2seq principles you learned today power: \"\n",
    "    \"‚Ä¢ 1+ billion daily translations (Google) \"\n",
    "    \"‚Ä¢ 1+ million developers (GitHub Copilot) \"\n",
    "    \"‚Ä¢ 100+ million ChatGPT users \"\n",
    "    \"‚Ä¢ Billions of email summaries \"\n",
    "    \"You now understand the foundation of modern AI!\",\n",
    "    COLOR_CURRENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Summary and Key Takeaways\n",
    "\n",
    "Let's consolidate everything you've learned about sequence-to-sequence models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary visualization\n",
    "def create_comprehensive_summary():\n",
    "    \"\"\"Final summary with all key concepts integrated.\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Create a grid layout for different summary aspects\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Problem ‚Üí Solution mapping\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    problems = ['Variable\\nLength', 'Information\\nBottleneck', 'Search\\nSpace']\n",
    "    solutions = ['Encoder-\\nDecoder', 'Attention\\nMechanism', 'Beam\\nSearch']\n",
    "    impact = [90, 95, 75]  # Impact scores\n",
    "    \n",
    "    bars = ax1.barh(range(len(problems)), impact, \n",
    "                   color=[COLOR_ENCODER, COLOR_ATTENTION, COLOR_PREDICT], alpha=0.8)\n",
    "    ax1.set_yticks(range(len(problems)))\n",
    "    ax1.set_yticklabels([f'{p}\\n‚Üí {s}' for p, s in zip(problems, solutions)])\n",
    "    ax1.set_xlabel('Impact Score')\n",
    "    ax1.set_title('Core Innovations', fontweight='bold')\n",
    "    ax1.set_xlim(0, 100)\n",
    "    \n",
    "    # 2. Timeline of breakthroughs\n",
    "    ax2 = fig.add_subplot(gs[0, 1:])\n",
    "    timeline_events = [\n",
    "        (2014, 'Seq2Seq\\nInvented', COLOR_ENCODER, 'Sutskever et al.'),\n",
    "        (2015, 'Attention\\nAdded', COLOR_ATTENTION, 'Bahdanau et al.'),\n",
    "        (2016, 'Google NMT\\nDeployed', COLOR_CONTEXT, '60% improvement'),\n",
    "        (2017, 'Transformer\\nReleased', COLOR_PREDICT, 'Attention is All You Need'),\n",
    "        (2018, 'BERT\\nReleased', COLOR_DECODER, 'Bidirectional training'),\n",
    "        (2020, 'GPT-3\\nReleased', COLOR_CURRENT, '175B parameters'),\n",
    "        (2022, 'ChatGPT\\nLaunched', COLOR_BOTTLENECK, '100M users in 2 months'),\n",
    "    ]\n",
    "    \n",
    "    years = [event[0] for event in timeline_events]\n",
    "    events = [event[1] for event in timeline_events]\n",
    "    colors_timeline = [event[2] for event in timeline_events]\n",
    "    descriptions = [event[3] for event in timeline_events]\n",
    "    \n",
    "    # Plot timeline\n",
    "    for i, (year, event, color, desc) in enumerate(timeline_events):\n",
    "        ax2.scatter(year, 1, s=200, color=color, alpha=0.8, edgecolors='black', linewidth=2)\n",
    "        \n",
    "        # Alternate high and low labels\n",
    "        y_text = 1.3 if i % 2 == 0 else 0.7\n",
    "        \n",
    "        ax2.annotate(f'{event}\\n{desc}', (year, 1),\n",
    "                    xytext=(0, 30 if i % 2 == 0 else -30), \n",
    "                    textcoords='offset points',\n",
    "                    ha='center', va='bottom' if i % 2 == 0 else 'top',\n",
    "                    fontsize=10, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', facecolor=color, alpha=0.3),\n",
    "                    arrowprops=dict(arrowstyle='->', color='gray', alpha=0.7))\n",
    "    \n",
    "    # Connect timeline with line\n",
    "    ax2.plot(years, [1]*len(years), '-', color='gray', alpha=0.5, linewidth=3)\n",
    "    \n",
    "    ax2.set_xlim(2013, 2023)\n",
    "    ax2.set_ylim(0.5, 1.5)\n",
    "    ax2.set_xlabel('Year', fontsize=12)\n",
    "    ax2.set_title('Seq2Seq ‚Üí Modern AI Timeline', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    ax2.set_yticks([])\n",
    "    \n",
    "    # 3. Performance comparison\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "    \n",
    "    models = ['Seq2Seq\\n(2014)', 'Attention\\n(2015)', 'Transformer\\n(2017)', \n",
    "              'BERT\\n(2018)', 'GPT-3\\n(2020)', 'ChatGPT\\n(2022)']\n",
    "    \n",
    "    metrics = {\n",
    "        'Translation (BLEU)': [25, 35, 52, 58, 65, 70],\n",
    "        'Text Generation': [20, 30, 45, 55, 75, 85],\n",
    "        'Understanding': [15, 25, 40, 70, 75, 80]\n",
    "    }\n",
    "    \n",
    "    x_models = np.arange(len(models))\n",
    "    width = 0.25\n",
    "    \n",
    "    colors_metrics = [COLOR_CONTEXT, COLOR_PREDICT, COLOR_ATTENTION]\n",
    "    \n",
    "    for i, (metric, scores) in enumerate(metrics.items()):\n",
    "        bars = ax3.bar(x_models + i*width, scores, width, \n",
    "                      color=colors_metrics[i], alpha=0.8, label=metric)\n",
    "    \n",
    "    ax3.set_xlabel('Model Evolution', fontsize=12)\n",
    "    ax3.set_ylabel('Performance Score', fontsize=12)\n",
    "    ax3.set_title('Performance Evolution Across Different Tasks', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xticks(x_models + width)\n",
    "    ax3.set_xticklabels(models, fontsize=10)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    ax3.set_ylim(0, 90)\n",
    "    \n",
    "    # 4. Key insights summary\n",
    "    ax4 = fig.add_subplot(gs[2, :])\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    insights_text = \"\"\"\n",
    "üéØ KEY INSIGHTS FROM WEEK 4:\n",
    "\n",
    "1. VARIABLE-LENGTH PROBLEM: Traditional RNNs can't handle input ‚â† output lengths\n",
    "   üí° Solution: Encoder-Decoder architecture separates understanding from generation\n",
    "\n",
    "2. INFORMATION BOTTLENECK: Single context vector loses information\n",
    "   üí° Solution: Attention mechanism keeps all encoder states accessible\n",
    "\n",
    "3. SEARCH CHALLENGE: Exponentially many possible outputs\n",
    "   üí° Solution: Beam search balances quality and computational efficiency\n",
    "\n",
    "4. MODERN RELEVANCE: These principles power today's AI systems\n",
    "   üí° Connection: ChatGPT, Copilot, and Google Translate all use these foundations\n",
    "\n",
    "üöÄ NEXT WEEK PREVIEW: Transformers take attention to the extreme with \"self-attention\"\n",
    "    and eliminate RNNs entirely for even better parallelization and performance!\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.5, 0.5, insights_text, ha='center', va='center',\n",
    "            transform=ax4.transAxes, fontsize=12,\n",
    "            bbox=dict(boxstyle='round,pad=1', facecolor=COLOR_PREDICT, alpha=0.2))\n",
    "    \n",
    "    plt.suptitle('Week 4 Complete: Understanding the Foundation of Modern AI', \n",
    "                fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "create_comprehensive_summary()\n",
    "\n",
    "# Final interactive element\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéì CONGRATULATIONS! You've mastered sequence-to-sequence models!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìã Self-Check - Can you now:\")\n",
    "print(\"  ‚úÖ Explain why variable-length I/O was a breakthrough?\")\n",
    "print(\"  ‚úÖ Describe the encoder-decoder architecture?\")\n",
    "print(\"  ‚úÖ Identify the information bottleneck problem?\")\n",
    "print(\"  ‚úÖ Implement attention mechanism from scratch?\")\n",
    "print(\"  ‚úÖ Use beam search for sequence generation?\")\n",
    "print(\"  ‚úÖ Connect these concepts to ChatGPT and modern AI?\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for Next Week:\")\n",
    "print(\"  üìñ Transformers: 'Attention Is All You Need'\")\n",
    "print(\"  üîß Self-attention and multi-head attention\")\n",
    "print(\"  ‚ö° Parallel processing (no more sequential RNNs!)\")\n",
    "print(\"  üåü Foundation of GPT, BERT, and all modern LLMs\")\n",
    "\n",
    "create_modern_context_box(\n",
    "    \"üèÖ Achievement Unlocked: You now understand the core technology behind \"\n",
    "    \"billion-dollar AI systems! The encoder-decoder + attention principles \"\n",
    "    \"you learned are used by Google, OpenAI, Microsoft, and every major AI company.\",\n",
    "    COLOR_CURRENT\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Lab Complete! Great work mastering these foundational concepts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Practice Exercises\n",
    "\n",
    "Ready to deepen your understanding? Try these exercises:\n",
    "\n",
    "### Beginner Level\n",
    "1. **Modify the encoder** to use different hidden sizes and observe how it affects the context vector\n",
    "2. **Experiment with attention types** - which works better for different query-key similarities?\n",
    "3. **Adjust beam size** in beam search and see the quality vs speed trade-off\n",
    "\n",
    "### Intermediate Level  \n",
    "4. **Implement teacher forcing** in the decoder and compare with inference-time generation\n",
    "5. **Add length normalization** to beam search scoring\n",
    "6. **Create attention visualizations** for your own sentence pairs\n",
    "\n",
    "### Advanced Level\n",
    "7. **Build a complete seq2seq translator** using PyTorch on a real dataset\n",
    "8. **Implement different attention mechanisms** (multiplicative, self-attention preview)\n",
    "9. **Connect to transformers** by implementing multi-head attention\n",
    "\n",
    "### Real-World Projects\n",
    "10. **Design a summarization system** for your domain of interest\n",
    "11. **Build a simple chatbot** using seq2seq principles\n",
    "12. **Create a code comment generator** that converts docstrings to code\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "### Foundational Papers (Must Read)\n",
    "- Sutskever et al. (2014): \"Sequence to Sequence Learning with Neural Networks\"\n",
    "- Bahdanau et al. (2015): \"Neural Machine Translation by Jointly Learning to Align and Translate\"\n",
    "- Luong et al. (2015): \"Effective Approaches to Attention-based Neural Machine Translation\"\n",
    "\n",
    "### Modern Context\n",
    "- Vaswani et al. (2017): \"Attention Is All You Need\" (next week!)\n",
    "- Wu et al. (2016): \"Google's Neural Machine Translation System\"\n",
    "\n",
    "### Interactive Learning\n",
    "- Jay Alammar's \"Visualizing A Neural Machine Translation Model\"\n",
    "- OpenAI's GPT papers for seeing how these concepts scaled\n",
    "- Hugging Face documentation for modern implementations\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:** The core insight of seq2seq is beautifully simple - separate understanding from generation, and let the model learn what to focus on. This simple idea revolutionized AI and powers the systems you use every day! üåü"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}