\documentclass[8pt,aspectratio=169,8pt]{beamer}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{algorithm2e}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{subfigure}
\usepackage{hyperref}

% Theme settings
\usetheme{Frankfurt}
\usecolortheme{seahorse}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]

% Custom colors
\definecolor{darkblue}{RGB}{0,51,102}
\definecolor{lightblue}{RGB}{173,216,230}
\definecolor{codegreen}{RGB}{0,128,0}
\definecolor{codegray}{RGB}{150,150,150}
\definecolor{codepurple}{RGB}{128,0,128}
\definecolor{backcolor}{RGB}{245,245,245}

% Code listing settings
\lstset{
    backgroundcolor=\color{backcolor},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    showstringspaces=false,
    frame=single,
    numbers=left,
    language=Python
}

% Include slide layouts
\input{../slide_layouts.tex}

\title[Week 10: Fine-tuning]{Natural Language Processing Course}
\subtitle{Week 10: Fine-tuning and Prompt Engineering}
\author{Joerg R. Osterrieder \\ \url{www.joergosterrieder.com}}
\date{}

\begin{document}

% Title page
\begin{frame}
    \titlepage
\end{frame}

\section{Week 10: Fine-tuning and Prompt Engineering}

% Title slide
\begin{frame}
    \centering
    \vspace{2cm}
    {\Large \textbf{Week 10}}\\
    \vspace{0.5cm}
    {\huge \textbf{Fine-tuning \& Prompt Engineering}}\\
    \vspace{1cm}
    {\large Making Models Do Exactly What You Want}
\end{frame}

% Motivation: The specificity problem
\begin{frame}[t]{Why GPT-3 Couldn't Write Good Legal Contracts}
    \textbf{2021: A law firm tried using GPT-3...}
    
    \vspace{0.5em}
    Prompt: "Write a software licensing agreement"
    
    Result: Generic, missed critical legal nuances, unusable\footnotemark
    
    \vspace{0.5em}
    \textbf{The problem:}
    \begin{itemize}
        \item GPT-3 knows about everything... but not deeply
        \item Trained on internet text, not legal documents
        \item Can't follow specific formatting requirements
        \item No domain expertise
    \end{itemize}
    
    \vspace{0.5em}
    \begin{center}
    \colorbox{red!20}{
        \parbox{0.8\textwidth}{
            \centering
            General models are jacks of all trades, masters of none
        }
    }
    \end{center}
    
    \vspace{0.5em}
    \textbf{Two solutions emerged:}
    \begin{enumerate}
        \item Fine-tune on legal documents
        \item Engineer better prompts
    \end{enumerate}
    
    \footnotetext{Composite example from multiple reported cases}
\end{frame}

% The adaptation landscape
\begin{frame}[t]{From General to Specific: The Adaptation Challenge}
    \centering
    \includegraphics[width=0.7\textwidth]{../figures/adaptation_methods.pdf}
    
    \vspace{0.5em}
    \textbf{The spectrum of adaptation:}
    \begin{itemize}
        \item Zero-shot: Just ask (often fails)
        \item Few-shot: Show examples (better)
        \item Prompt engineering: Craft perfect instructions (good)
        \item Fine-tuning: Update model weights (best for specific tasks)
    \end{itemize}
\end{frame}

% Real-world impact
\begin{frame}[t]{Fine-tuning and Prompting in Production (2024)}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{Fine-tuning Success:}
            \begin{itemize}
                \item Bloomberg GPT: Finance\footnotemark
                \item Med-PaLM 2: Medical diagnosis
                \item Codex: GitHub Copilot
                \item ChatGPT: From GPT-3.5 base
                \item Domain accuracy: 70\% → 95\%
            \end{itemize}
            
            \vspace{0.5em}
            \textbf{Prompt Engineering:}
            \begin{itemize}
                \item No training needed
                \item Instant deployment
                \item Version control friendly
                \item Cost: \$0 training
                \item Performance: 60-80\% of fine-tuning
            \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \textbf{Modern Methods:}
            \begin{itemize}
                \item LoRA: 0.1\% parameters\footnotemark
                \item Prefix tuning: Frozen model
                \item Instruction tuning: Task generalization
                \item RLHF: Preference alignment
                \item Adapter layers: Modular skills
            \end{itemize}
            
            \vspace{0.5em}
            \textbf{Business Impact:}
            \begin{itemize}
                \item 10x faster deployment
                \item 90\% less compute needed
                \item Domain expert performance
                \item Customization at scale
            \end{itemize}
        \end{column}
    \end{columns}
    
    \vspace{0.5em}
    \begin{center}
    \colorbox{lightblue!30}{
        \parbox{0.8\textwidth}{
            \centering
            2024: Every company has a fine-tuned model or engineered prompts
        }
    }
    \end{center}
    
    \footnotetext[1]{50B parameters trained on financial data}
    \footnotetext[2]{Low-Rank Adaptation - Hu et al. (2021)}
\end{frame}

% Learning objectives
\begin{frame}[t]{Week 10: What You'll Master}
    \textbf{By the end of this week, you will:}
    \begin{itemize}
        \item \textbf{Understand} when to fine-tune vs prompt
        \item \textbf{Implement} efficient fine-tuning (LoRA)
        \item \textbf{Master} prompt engineering patterns
        \item \textbf{Design} instruction datasets
        \item \textbf{Build} domain-specific assistants
    \end{itemize}
    
    \vspace{0.5em}
    \begin{center}
    \colorbox{lightblue!30}{
        \parbox{0.8\textwidth}{
            \centering
            \textbf{Core Insight:} Small changes → Big behavioral shifts
        }
    }
    \end{center}
\end{frame}

% Fine-tuning basics
\begin{frame}[t]{Fine-tuning: Teaching New Tricks to Old Models}
    \textbf{Traditional fine-tuning:}
    \begin{enumerate}
        \item Start with pre-trained model (e.g., BERT)
        \item Add task-specific head
        \item Train on your data
        \item Update ALL parameters
    \end{enumerate}
    
    \vspace{0.5em}
    \textbf{The problems:}
    \begin{itemize}
        \item Catastrophic forgetting
        \item Needs lots of GPU memory
        \item Slow and expensive
        \item One model per task
    \end{itemize}
    
    \vspace{0.5em}
    \textbf{Example - Customer Support Bot:}
    \begin{itemize}
        \item Base model: 7B parameters = 28GB
        \item Fine-tuning: 8 A100 GPUs, 2 days
        \item Cost: \$500
        \item Result: 95\% accuracy on support tickets
    \end{itemize}
    
    \vspace{0.5em}
    \begin{center}
    \colorbox{yellow!20}{
        \parbox{0.8\textwidth}{
            \centering
            Full fine-tuning works but doesn't scale
        }
    }
    \end{center}
\end{frame}

% LoRA explanation
\begin{frame}[t]{LoRA: The Efficiency Revolution}
    \centering
    \includegraphics[width=0.65\textwidth]{../figures/lora_explanation.pdf}
    
    \vspace{0.5em}
    \textbf{Key insight: Most weight updates are low-rank!}
    \begin{itemize}
        \item Instead of updating W (d×d), update A (d×r) and B (r×d)
        \item r << d (typically r=8 while d=4096)
        \item Only 0.1\% of parameters!
        \item Multiple LoRAs can be swapped
    \end{itemize}
\end{frame}

% LoRA implementation
\begin{frame}[fragile]{Implementing LoRA}
    \begin{columns}[T]
        \column{0.55\textwidth}

\begin{lstlisting}[language=Python,basicstyle=\ttfamily\tiny]
import torch
import torch.nn as nn
import torch.nn.functional as F

class LoRALayer(nn.Module):
    def __init__(self, in_features, out_features, rank=8, alpha=16):
        """LoRA adapter for linear layers"""
        super().__init__()
        self.rank = rank
        self.alpha = alpha
        self.scaling = alpha / rank
        
        self.weight = nn.Parameter(torch.randn(out_features, in_features))
        self.weight.requires_grad = False
        
        self.lora_A = nn.Parameter(torch.randn(rank, in_features))
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))
        
        nn.init.normal_(self.lora_A, std=0.02)
        
    def forward(self, x):
        """Forward pass with LoRA adaptation"""
        out = F.linear(x, self.weight)
        
        lora_out = x @ self.lora_A.T @ self.lora_B.T
        
        return out + self.scaling * lora_out
    
    def merge_weights(self):
        """Merge LoRA weights for deployment"""
        self.weight.data += self.scaling * (self.lora_B @ self.lora_A)
        
class LoRAModel(nn.Module):
    def __init__(self, base_model, rank=8, target_modules=['q_proj', 'v_proj']):
        """Add LoRA to existing model"""
        super().__init__()
        self.base_model = base_model
        
        for name, module in base_model.named_modules():
            if any(target in name for target in target_modules):
                if isinstance(module, nn.Linear):
                    lora_layer = LoRALayer(
                        module.in_features, 
                        module.out_features,
                        rank=rank
                    )
                    lora_layer.weight.data = module.weight.data.clone()
                    
                    parent_name, child_name = name.rsplit('.', 1)
                    parent = base_model.get_submodule(parent_name)
                    setattr(parent, child_name, lora_layer)
\end{lstlisting}
        \column{0.43\textwidth}

        \codeexplanation{
            \textbf{LoRA Benefits:}
            \begin{itemize}
                \item Memory: 10,000x less
                \item Speed: 3x faster training
                \item Storage: 3MB vs 30GB
                \item Swappable: Multiple tasks
            \end{itemize}
            
            \vspace{0.3em}
            \textbf{Hyperparameters:}
            \begin{itemize}
                \item Rank: 4-64 (8 common)
                \item Alpha: Scaling factor
                \item Target: Usually attention
                \item Learning rate: 1e-4
            \end{itemize}
            
            \vspace{0.3em}
            \textbf{Results Match Full FT:}
            \begin{itemize}
                \item 0.1\% parameters
                \item 99\% performance
                \item No forgetting
            \end{itemize}
        }
    \end{columns}
\end{frame}

% Prompt engineering basics
\begin{frame}[t]{Prompt Engineering: Programming with Natural Language}
    \textbf{The prompt is your program:}
    
    \vspace{0.5em}
    \textbf{Basic → Advanced:}
    
    \begin{enumerate}
        \item \colorbox{red!20}{Basic:} "Summarize this text"
        
        \item \colorbox{yellow!20}{Better:} "Summarize this text in 3 bullet points"
        
        \item \colorbox{green!20}{Good:} "You are an expert editor. Summarize this text in exactly 3 bullet points, each under 20 words, capturing the key insights."
        
        \item \colorbox{green!20}{Excellent:} "You are an expert editor at The Economist. Your task is to summarize the following text.
        
        Requirements:
        - Exactly 3 bullet points
        - Each under 20 words  
        - Focus on actionable insights
        - Use active voice
        - Avoid jargon"
    \end{enumerate}
    
    \vspace{0.5em}
    \begin{center}
    \colorbox{lightblue!30}{
        \parbox{0.8\textwidth}{
            \centering
            Specificity and structure dramatically improve output quality
        }
    }
    \end{center}
\end{frame}

% Prompt patterns
\begin{frame}[t]{Prompt Engineering Patterns That Work}
    \centering
    \includegraphics[width=0.65\textwidth]{../figures/prompt_patterns.pdf}
    
    \vspace{0.5em}
    \textbf{Proven patterns:}
    \begin{itemize}
        \item Role: "You are an expert..."
        \item Task: Clear, specific instructions
        \item Context: Relevant background
        \item Examples: Show desired format
        \item Constraints: Length, style, format
    \end{itemize}
\end{frame}

% Advanced prompting
\begin{frame}[fragile]{Advanced Prompt Engineering Techniques}
    \begin{columns}[T]
                \column{0.60\textwidth}

\begin{lstlisting}[language=Python,basicstyle=\ttfamily\tiny]
class PromptTemplate:
    """Advanced prompt engineering patterns"""
    
    @staticmethod
    def chain_of_thought(question):
        """CoT prompting for reasoning"""
        return f"""Q: {question}
Let's approach this step-by-step:
1) First, let's understand what we're asked...
2) Next, let's identify the key information...
3) Now, let's work through the solution...
4) Finally, let's verify our answer...

A: [Model completes the reasoning]"""
    
    @staticmethod
    def few_shot_with_reasoning(examples, query):
        """Few-shot with explanations"""
        prompt = "I'll solve these problems step by step.\n\n"
        
        for ex in examples:
            prompt += f"Problem: {ex['problem']}\n"
            prompt += f"Reasoning: {ex['reasoning']}\n"
            prompt += f"Answer: {ex['answer']}\n\n"
            
        prompt += f"Problem: {query}\n"
        prompt += "Reasoning: "
        return prompt
    
    @staticmethod
    def self_consistency(question, n_samples=5):
        """Multiple reasoning paths"""
        prompt = f"""Q: {question}

I'll solve this {n_samples} different ways to ensure accuracy:

Approach 1: [Model generates]
Approach 2: [Model generates]
...

Final answer based on consistency: [Model concludes]"""
        return prompt
    
    @staticmethod
    def structured_output(task, schema):
        """Force specific output format"""
        return f"""{task}

Output your response in the following JSON format:
[JSON schema here]

Ensure all fields are filled and types match exactly."""

def optimize_prompt(base_prompt, examples, constraints):
    """Iterative prompt improvement"""
    
    optimized = "You are a world-class expert in this domain.\\n\\n"
    
    if examples:
        optimized += "Here are some examples:\\n"
        for ex in examples:
            optimized += f"Input: [input]\\nOutput: [output]\\n\\n"
    
    optimized += f"Task: [base prompt]\\n\\n"
    
    if constraints:
        optimized += "Requirements:\\n"
        for constraint in constraints:
            optimized += f"- [constraint]\\n"
    
    optimized += "\\nThink step by step and explain your reasoning."
    
    return optimized
\end{lstlisting}
                \column{0.38\textwidth}

        \codeexplanation{
            \textbf{Key Techniques:}
            \begin{itemize}
                \item Chain-of-thought: +20\% on reasoning\footnotemark
                \item Self-consistency: Multiple paths
                \item Few-shot: Examples guide format
                \item Structured: JSON/XML output
            \end{itemize}
            
            \vspace{0.3em}
            \textbf{Prompt Optimization:}
            \begin{itemize}
                \item Test variations
                \item Measure performance
                \item Iterate systematically
                \item Version control prompts
            \end{itemize}
            
            \footnotetext{Wei et al. (2022) "Chain-of-Thought"}
        }
    \end{columns}
\end{frame}

% Instruction tuning
\begin{frame}[t]{Instruction Tuning: Teaching Models to Follow Instructions}
    \textbf{The breakthrough: Train on instruction-following itself}
    
    \vspace{0.5em}
    \textbf{Traditional fine-tuning:}
    \begin{itemize}
        \item Task: Sentiment analysis
        \item Data: (text, label) pairs
        \item Model learns: One specific task
    \end{itemize}
    
    \vspace{0.5em}
    \textbf{Instruction tuning:}\footnotemark
    \begin{itemize}
        \item Task: Follow any instruction
        \item Data: (instruction, input, output) triples
        \item Model learns: Generalize to new tasks!
    \end{itemize}
    
    \vspace{0.5em}
    \textbf{Example training data:}
    \begin{small}
    \begin{itemize}
        \item Instruction: "Translate to French" → Input: "Hello" → Output: "Bonjour"
        \item Instruction: "Summarize" → Input: [article] → Output: [summary]
        \item Instruction: "Write code" → Input: [spec] → Output: [code]
    \end{itemize}
    \end{small}
    
    \vspace{0.5em}
    \begin{center}
    \colorbox{green!20}{
        \parbox{0.8\textwidth}{
            \centering
            Result: Zero-shot performance on completely new tasks!
        }
    }
    \end{center}
    
    \footnotetext{Wei et al. (2021) "FLAN"; Ouyang et al. (2022) "InstructGPT"}
\end{frame}

% Comparison of methods
\resultslide{Fine-tuning vs Prompting: When to Use What}{
    \centering
    \includegraphics[width=0.65\textwidth]{../figures/finetuning_vs_prompting.pdf}
}{
    \begin{itemize}
        \item Limited data: Use prompting
        \item Need 95\%+ accuracy: Fine-tune
        \item Rapid iteration: Prompting
        \item Production scale: Fine-tune with LoRA
        \item Best of both: Instruction-tuned + prompts
    \end{itemize}
}

% RLHF and alignment
\begin{frame}[t]{RLHF: Aligning Models with Human Preferences}
    \textbf{The problem: Models don't know what humans actually want}
    
    \vspace{0.5em}
    \textbf{Reinforcement Learning from Human Feedback:}\footnotemark
    \begin{enumerate}
        \item Generate multiple outputs
        \item Humans rank them
        \item Train reward model
        \item Use RL to optimize for human preferences
    \end{enumerate}
    
    \vspace{0.5em}
    \centering
    \includegraphics[width=0.7\textwidth]{../figures/rlhf_process.pdf}
    
    \vspace{0.5em}
    \textbf{Impact:}
    \begin{itemize}
        \item ChatGPT vs GPT-3: Night and day difference
        \item Reduces harmful outputs by 90\%
        \item Makes models helpful, harmless, honest
    \end{itemize}
    
    \footnotetext{Christiano et al. (2017); Ouyang et al. (2022)}
\end{frame}

% Practical guidelines
\begin{frame}[t]{Choosing Your Adaptation Strategy}
    \centering
    \includegraphics[width=0.65\textwidth]{../figures/adaptation_decision_tree.pdf}
    
    \vspace{0.5em}
    \textbf{Quick decision guide:}
    \begin{itemize}
        \item $<$100 examples: Prompt engineering
        \item 100-1K examples: Few-shot + prompting  
        \item 1K-10K examples: LoRA fine-tuning
        \item $>$10K examples: Full fine-tuning
        \item Need control: RLHF/DPO
    \end{itemize}
\end{frame}

% Exercise
\begin{frame}[t]{Week 10 Exercise: Build a Domain Expert Assistant}
    \textbf{Your Mission:} Create specialized assistant using both approaches
    
    \vspace{0.5em}
    \textbf{Part 1: Prompt Engineering}
    \begin{itemize}
        \item Choose domain (medical, legal, finance, etc.)
        \item Design systematic prompts
        \item Test role, CoT, few-shot patterns
        \item Measure accuracy on test cases
        \item Iterate to improve
    \end{itemize}
    
    \vspace{0.5em}
    \textbf{Part 2: LoRA Fine-tuning}
    \begin{itemize}
        \item Collect 1K domain examples
        \item Implement LoRA adapter
        \item Fine-tune base model
        \item Compare with prompting approach
        \item Measure speed/cost/quality
    \end{itemize}
    
    \vspace{0.5em}
    \textbf{Part 3: Hybrid Approach}
    \begin{itemize}
        \item Instruction-tune with domain data
        \item Design prompts for fine-tuned model
        \item Build evaluation framework
        \item Deploy and test with users
    \end{itemize}
    
    \vspace{0.5em}
    \textbf{You'll discover:} The sweet spot between effort and performance!
\end{frame}

% Summary
\begin{frame}[t]{Key Takeaways: Specialization Strategies}
    \textbf{What we learned:}
    \begin{itemize}
        \item General models need adaptation
        \item Prompting: Fast, flexible, limited
        \item Fine-tuning: Powerful but expensive
        \item LoRA: Best of both worlds
        \item Instruction tuning: Generalization
    \end{itemize}
    
    \vspace{0.5em}
    \textbf{The evolution:}
    \begin{center}
    \colorbox{lightblue!30}{
        \parbox{0.8\textwidth}{
            \centering
            Full fine-tuning → Prompting → LoRA → Instruction tuning → RLHF
        }
    }
    \end{center}
    
    \vspace{0.5em}
    \textbf{Why it matters:}
    \begin{itemize}
        \item Makes LLMs practical for business
        \item Enables rapid customization
        \item Reduces deployment costs 100x
    \end{itemize}
    
    \vspace{0.5em}
    \textbf{Next week: Efficiency and Deployment}
    
    How do we run these massive models on phones and edge devices?
\end{frame}

% References
\begin{frame}[t]{References and Further Reading}
    \textbf{Foundational Papers:}
    \begin{itemize}
        \item Hu et al. (2021). "LoRA: Low-Rank Adaptation of Large Language Models"
        \item Wei et al. (2021). "Finetuned Language Models Are Zero-Shot Learners"
        \item Ouyang et al. (2022). "Training language models to follow instructions"
    \end{itemize}
    
    \textbf{Prompt Engineering:}
    \begin{itemize}
        \item Liu et al. (2023). "Pre-train, Prompt, and Predict"
        \item White et al. (2023). "A Prompt Pattern Catalog"
        \item Zhou et al. (2023). "Large Language Models Are Human-Level Prompt Engineers"
    \end{itemize}
    
    \textbf{Practical Resources:}
    \begin{itemize}
        \item OpenAI Fine-tuning Guide
        \item Anthropic's Constitutional AI papers
        \item PEFT library (Hugging Face)
    \end{itemize}
\end{frame}
\end{document}
